{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGt-70QClelr"
   },
   "source": [
    "# Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16332,
     "status": "ok",
     "timestamp": 1644951543264,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "P-rSKk25BOni",
    "outputId": "2aea39bc-daf5-49a0-d0c0-2f7f17ec4341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW2tyXizlidj"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1644955060730,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "dtukYC2LpUEX"
   },
   "outputs": [],
   "source": [
    "#@title Paths\n",
    "ROOT = 'drive/MyDrive/fall21/snowcast/realtime/'\n",
    "PRED_PATH = ROOT + 'predictions/'\n",
    "\n",
    "MODIS_CNN_PATH = ROOT + 'model_32_18_8_3_0.13_50_1399_0.0001' #'modis_model'\n",
    "SENTINEL_CNN_PATH = ROOT + 'sentinel_model' # TODO\n",
    "LM_PATH = ROOT + 'lm.joblib'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 49680,
     "status": "ok",
     "timestamp": 1644951592940,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "yrYlWjZur2kD"
   },
   "outputs": [],
   "source": [
    "#@title Installs\n",
    "!apt install gdal-bin python-gdal python3-gdal &> /dev/null\n",
    "!apt install python3-rtree &> /dev/null\n",
    "!pip install git+git://github.com/geopandas/geopandas.git &> /dev/null\n",
    "!pip install descartes &> /dev/null\n",
    "!pip install geopandas rioxarray &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Matt's Paths\n",
    "ROOT = 'C:/Users/Matt/Documents/Python Scripts/SnowComp/realtime/'\n",
    "PATH_DBX = \"C:/Users/Matt/Dropbox/SnowComp/\"\n",
    "\n",
    "MODIS_CNN_PATH = ROOT + 'model_32_18_8_3_0.13_50_1399_0.0001' #'modis_model'\n",
    "SENTINEL_CNN_PATH = ROOT + 'model_sent_32_18_8_7_0.13_16_98_0.0003' # TODO\n",
    "LM_PATH = ROOT + 'lm.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1644951974912,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "919OGliilhTw"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import sys\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import sentinel_cnn\n",
    "importlib.reload(sentinel_cnn)\n",
    "from modis_cnn import Net as ModisNet\n",
    "from sentinel_cnn import Net as SentNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5amGBaJKxNYP"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 2996,
     "status": "ok",
     "timestamp": 1644952353562,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "iC07CaFwqtzJ"
   },
   "outputs": [],
   "source": [
    "#@title Get prediction df\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_day_of_season(doy):\n",
    "    return doy + 365 - 335 if doy < 335 else doy - 335\n",
    "\n",
    "def add_time_cols(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['doy'] = df['date'].dt.dayofyear\n",
    "    df['dos'] = df['doy'].apply(get_day_of_season)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['season'] = df['year']\n",
    "    df.loc[df['doy'] < 335, 'season'] -= 1\n",
    "    return df\n",
    "\n",
    "def clean_train_test(df, id_col='station_id', metadata_df=None):\n",
    "    df = pivot_df(df, id_col)\n",
    "    if metadata_df is not None:\n",
    "        df = df.merge(metadata_df)\n",
    "    return add_time_cols(df)\n",
    "\n",
    "def minmaxscaler(x, params= None):\n",
    "    if not params:\n",
    "        print(\"min\", round(x.min(),3), \"max\", round(x.max(),3))\n",
    "        x = (x - x.min())/(x.max() - x.min())\n",
    "    else:\n",
    "        print(\"loaded min\", round(params[0],3), \"loaded max\", round(params[1],3))\n",
    "        x = (x - params[0])/(params[1] - params[0])\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "submission_format = pd.read_csv(ROOT + 'submission_format.csv')\\\n",
    "                      .rename({'Unnamed: 0': 'cell_id'}, axis=1)\n",
    "to_predict = clean_train_test(submission_format, 'cell_id')\n",
    "predict_date = max([x for x in to_predict['date'] if x < datetime.today()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1644953434747,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "5sJ-WCtjlglM",
    "outputId": "516e097e-fcc0-470e-b395-86d8ab53a1d3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 dim: 19\n",
      "mp0 dim: 17\n",
      "c2 dim: 15\n",
      "mp1 dim: 13\n",
      "c3 dim: 11\n",
      "mp2 dim: 9\n",
      "flattened_dim 648\n"
     ]
    }
   ],
   "source": [
    "#@title Load MODIS CNN\n",
    "net_kwargs = {'cdim1': 32,\n",
    "              'cdim2': 18,\n",
    "              'cdim3': 8,\n",
    "              'kernel_sz': 3,\n",
    "              'dropout': 0.13,\n",
    "              'ldim': 50}\n",
    "# net_kwargs = {'cdim1': 128,\n",
    "#               'cdim2': 30,\n",
    "#               'cdim3': 15,\n",
    "#               'kernel_sz': 3,\n",
    "#               'dropout': 0.13,\n",
    "#               'ldim': 70}\n",
    "\n",
    "modis_net = ModisNet(**net_kwargs)\n",
    "modis_net.load_state_dict(torch.load(MODIS_CNN_PATH))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "_ = modis_net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIS Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2022-02-10\"\n",
    "rt_path = PATH_DBX + 'realtimeData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_ds = np.load(rt_path +\"Modis_sub_\"+DATE+\".npy\")\n",
    "with open(rt_path + \"Modis_sub_meta.pkl\", 'rb') as handle:\n",
    "    modis_meta = pickle.load( handle)\n",
    "    \n",
    "modis_meta = list(map(lambda x: x[0], modis_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put cell_id /modis image in dictionary\n",
    "# iterate through submission rows, reconstruct ordered numpy array\n",
    "modis_ordered = np.zeros_like(modis_ds)\n",
    "modis_dict = {}\n",
    "for i, elem in enumerate(modis_meta):\n",
    "    modis_dict[elem] = modis_ds[i]\n",
    "\n",
    "for i, cell_id in enumerate(submission_format['cell_id']):\n",
    "    modis_ordered[i] = modis_dict[cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1644953545231,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "UMDTKeIZx_Dj",
    "outputId": "cdb4ef33-ac14-42fd-baed-e4aa688f06a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "#@title Get Modis CNN predictions\n",
    "def predict(cnn, x, as_numpy=False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cnn.eval()\n",
    "    x = x.type(torch.FloatTensor).to(device)\n",
    "    output = cnn(x)\n",
    "    if as_numpy:\n",
    "        output = output.flatten().cpu().detach().numpy() #detach removes gradients (bad)\n",
    "        \n",
    "    cnn.train()\n",
    "    return output.squeeze()\n",
    "\n",
    "# cnn_preds = predict(modis_net.cuda(), torch.Tensor(modis_ds).cuda(), as_numpy=True)\n",
    "\n",
    "modis_preds = predict(modis_net, torch.Tensor(modis_ordered), as_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KTiEyMx1oMO"
   },
   "source": [
    "### Sentinel Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded min -57.906 loaded max 18.57\n"
     ]
    }
   ],
   "source": [
    "sent_sub = np.load(rt_path + \"sent_pp_sub1\"+ DATE +\".npy\") \n",
    "sent_sub = minmaxscaler(sent_sub, [-57.906, 18.57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Matt/Documents/Python Scripts/SnowComp/realtime/sentinel_model'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTINEL_CNN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cellView": "form",
    "id": "MT1jdBoFf7gF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 11 11\n",
      "c1 dim: 35\n",
      "mp0 dim: 33\n",
      "c2 dim: 27\n",
      "mp1 dim: 25\n",
      "c3 dim: 19\n",
      "c3_ dim: 13\n",
      "c3__ dim: 13\n",
      "mp2 dim: 11\n",
      "flattened_dim 968\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m net_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdim1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      3\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdim2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m18\u001b[39m,\n\u001b[0;32m      4\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdim3\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_sz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m      6\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.13\u001b[39m,\n\u001b[0;32m      7\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mldim\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m16\u001b[39m}\n\u001b[0;32m      9\u001b[0m sent_net \u001b[38;5;241m=\u001b[39m SentNet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnet_kwargs)\n\u001b[1;32m---> 10\u001b[0m sent_net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSENTINEL_CNN_PATH\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m _ \u001b[38;5;241m=\u001b[39m sent_net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[0;32m    606\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m--> 607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    881\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m--> 882\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:857\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    855\u001b[0m data_type, key, location, size \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m--> 857\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    858\u001b[0m storage \u001b[38;5;241m=\u001b[39m loaded_storages[key]\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m storage\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:846\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    843\u001b[0m dtype \u001b[38;5;241m=\u001b[39m data_type(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    845\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, size, dtype)\u001b[38;5;241m.\u001b[39mstorage()\n\u001b[1;32m--> 846\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:151\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 151\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    153\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\serialization.py:135\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    132\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    136\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    140\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#@title Load Sentinel CNN\n",
    "net_kwargs = {'cdim1': 32,\n",
    "              'cdim2': 18,\n",
    "              'cdim3': 8,\n",
    "              'kernel_sz': 7,\n",
    "              'dropout': 0.13,\n",
    "              'ldim': 16}\n",
    "\n",
    "sent_net = SentNet(**net_kwargs)\n",
    "sent_net.load_state_dict(torch.load(SENTINEL_CNN_PATH))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "_ = sent_net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1644952243810,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "4Mj8YGW-p1LJ",
    "outputId": "75e9cfe3-fdd0-437f-a9d4-6a8bbf650218"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "#@title Get Sentinel CNN predictions\n",
    "sent_preds = predict(sent_net, torch.Tensor(dataset), as_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sstp_6gNzBEM"
   },
   "outputs": [],
   "source": [
    "# TODO Matt: add in index to match MODIS predictions with dates/locations\n",
    "# TODO Matt: add in index to match Sentinel predictions with dates/locations\n",
    "\n",
    "def format_rf(df):\n",
    "    df['dos_2'] = df['dos'] ** 2\n",
    "    return df\n",
    "\n",
    "pred_df = format_rf(to_predict[to_predict['date'] == pd.to_datetime(predict_date)])\n",
    "\n",
    "modis_preds = np.random.randint(0, 20, len(pred_df)) # TODO delete\n",
    "sent_preds = np.random.randint(0, 20, len(pred_df))  # TODO delete\n",
    "\n",
    "pred_df['modis_pred'] = modis_preds\n",
    "pred_df['sent_pred'] = sent_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lt4eR6XPp1Gr"
   },
   "outputs": [],
   "source": [
    "#@title Get lm predictions\n",
    "def format_rf(df):\n",
    "    df['dos_2'] = df['dos'] ** 2\n",
    "    return df\n",
    "\n",
    "lm = joblib.load(LM_PATH)\n",
    "pred_df['snowpack'] = lm.predict(pred_df[['dos', 'dos_2', 'sent_pred', 'modis_pred']])\n",
    "pred_df.loc[pred_df['snowpack'] < 0, 'snowpack'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 4845,
     "status": "ok",
     "timestamp": 1644955075041,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "iRRgvMNCp1I3"
   },
   "outputs": [],
   "source": [
    "#@title Write predictions\n",
    "def write_formatted_preds(preds_df, outpath):\n",
    "    preds_df = preds_df[['cell_id', 'date', 'snowpack']]\n",
    "    preds_df['date'] = preds_df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    submission = preds_df.pivot(index='cell_id', columns='date', values='snowpack')\\\n",
    "                        .reset_index()\\\n",
    "                        .sort_values('cell_id')\n",
    "    \n",
    "    assert sorted(submission.columns) == sorted(submission_format.columns)\n",
    "    assert sorted(submission['cell_id']) == sorted(submission_format['cell_id'])\n",
    "\n",
    "    submission.to_csv(PRED_PATH + '%s.csv' % outpath, index=False)\n",
    "\n",
    "\n",
    "out_df = pd.concat([to_predict, pred_df[to_predict.columns]])\\\n",
    "           .drop_duplicates(subset=['cell_id', 'date'], keep='last')\n",
    "x = write_formatted_preds(out_df[['cell_id', 'snowpack', 'date']], \n",
    "                      datetime.today().strftime('%Y%m%d_preds.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6zhLt88p1D8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMsMkHPdxeqL8J9FubA6pBd",
   "collapsed_sections": [
    "qGt-70QClelr"
   ],
   "name": "realtime.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
