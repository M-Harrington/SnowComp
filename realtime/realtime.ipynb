{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGt-70QClelr"
   },
   "source": [
    "# Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16332,
     "status": "ok",
     "timestamp": 1644951543264,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "P-rSKk25BOni",
    "outputId": "2aea39bc-daf5-49a0-d0c0-2f7f17ec4341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW2tyXizlidj"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1644955060730,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "dtukYC2LpUEX"
   },
   "outputs": [],
   "source": [
    "#@title Paths\n",
    "ROOT = 'drive/MyDrive/fall21/snowcast/realtime/'\n",
    "PRED_PATH = ROOT + 'predictions/'\n",
    "\n",
    "MODIS_CNN_PATH = ROOT + 'model_32_18_8_3_0.13_50_1399_0.0001' #'modis_model'\n",
    "SENTINEL_CNN_PATH = ROOT + 'sentinel_model' # TODO\n",
    "LM_PATH = ROOT + 'lm.joblib'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 49680,
     "status": "ok",
     "timestamp": 1644951592940,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "yrYlWjZur2kD"
   },
   "outputs": [],
   "source": [
    "#@title Installs\n",
    "!apt install gdal-bin python-gdal python3-gdal &> /dev/null\n",
    "!apt install python3-rtree &> /dev/null\n",
    "!pip install git+git://github.com/geopandas/geopandas.git &> /dev/null\n",
    "!pip install descartes &> /dev/null\n",
    "!pip install geopandas rioxarray &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Matt's Paths\n",
    "ROOT = 'C:/Users/Matt/Documents/Python Scripts/SnowComp/realtime/'\n",
    "PATH_DBX = \"C:/Users/Matt/Dropbox/SnowComp/\"\n",
    "\n",
    "MODIS_CNN_PATH = ROOT + 'model_32_18_8_3_0.13_50_1399_0.0001' #'modis_model'\n",
    "SENTINEL_CNN_PATH = ROOT + 'model_sent_32_18_8_7_0.13_16_98_0.0003' # TODO\n",
    "LM_PATH = ROOT + 'lm.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1644951974912,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "919OGliilhTw"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import sys\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import sentinel_cnn\n",
    "importlib.reload(sentinel_cnn)\n",
    "from modis_cnn import Net as ModisNet\n",
    "from sentinel_cnn import Net as SentNet\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5amGBaJKxNYP"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 2996,
     "status": "ok",
     "timestamp": 1644952353562,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "iC07CaFwqtzJ"
   },
   "outputs": [],
   "source": [
    "#@title Get prediction df\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_day_of_season(doy):\n",
    "    return doy + 365 - 335 if doy < 335 else doy - 335\n",
    "\n",
    "def add_time_cols(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['doy'] = df['date'].dt.dayofyear\n",
    "    df['dos'] = df['doy'].apply(get_day_of_season)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['season'] = df['year']\n",
    "    df.loc[df['doy'] < 335, 'season'] -= 1\n",
    "    return df\n",
    "\n",
    "def clean_train_test(df, id_col='station_id', metadata_df=None):\n",
    "    df = pivot_df(df, id_col)\n",
    "    if metadata_df is not None:\n",
    "        df = df.merge(metadata_df)\n",
    "    return add_time_cols(df)\n",
    "\n",
    "def minmaxscaler(x, params= None):\n",
    "    if not params:\n",
    "        print(\"min\", round(x.min(),3), \"max\", round(x.max(),3))\n",
    "        x = (x - x.min())/(x.max() - x.min())\n",
    "    else:\n",
    "        print(\"loaded min\", round(params[0],3), \"loaded max\", round(params[1],3))\n",
    "        x = (x - params[0])/(params[1] - params[0])\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "submission_format = pd.read_csv(ROOT + 'submission_format.csv')\\\n",
    "                      .rename({'Unnamed: 0': 'cell_id'}, axis=1)\n",
    "to_predict = clean_train_test(submission_format, 'cell_id')\n",
    "predict_date = max([x for x in to_predict['date'] if x < datetime.today()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1644953434747,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "5sJ-WCtjlglM",
    "outputId": "516e097e-fcc0-470e-b395-86d8ab53a1d3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 dim: 19\n",
      "mp0 dim: 17\n",
      "c2 dim: 15\n",
      "mp1 dim: 13\n",
      "c3 dim: 11\n",
      "mp2 dim: 9\n",
      "flattened_dim 648\n"
     ]
    }
   ],
   "source": [
    "#@title Load MODIS CNN\n",
    "net_kwargs = {'cdim1': 32,\n",
    "              'cdim2': 18,\n",
    "              'cdim3': 8,\n",
    "              'kernel_sz': 3,\n",
    "              'dropout': 0.13,\n",
    "              'ldim': 50}\n",
    "# net_kwargs = {'cdim1': 128,\n",
    "#               'cdim2': 30,\n",
    "#               'cdim3': 15,\n",
    "#               'kernel_sz': 3,\n",
    "#               'dropout': 0.13,\n",
    "#               'ldim': 70}\n",
    "\n",
    "modis_net = ModisNet(**net_kwargs)\n",
    "modis_net.load_state_dict(torch.load(MODIS_CNN_PATH))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "_ = modis_net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIS Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2022-02-10\"\n",
    "rt_path = PATH_DBX + 'realtimeData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_ds = np.load(rt_path +\"Modis_sub_\"+DATE+\".npy\")\n",
    "with open(rt_path + \"Modis_sub_meta.pkl\", 'rb') as handle:\n",
    "    modis_meta = pickle.load( handle)\n",
    "    \n",
    "modis_meta = list(map(lambda x: x[0], modis_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put cell_id /modis image in dictionary\n",
    "# iterate through submission rows, reconstruct ordered numpy array\n",
    "modis_ordered = np.zeros_like(modis_ds)\n",
    "modis_dict = {}\n",
    "for i, elem in enumerate(modis_meta):\n",
    "    modis_dict[elem] = modis_ds[i]\n",
    "\n",
    "for i, cell_id in enumerate(submission_format['cell_id']):\n",
    "    modis_ordered[i] = modis_dict[cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1644953545231,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "UMDTKeIZx_Dj",
    "outputId": "cdb4ef33-ac14-42fd-baed-e4aa688f06a4"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vals_sub\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# cnn_preds = predict(modis_net.cuda(), torch.Tensor(modis_ds).cuda(), as_numpy=True)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m modis_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodis_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodis_ordered\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(cnn, x, as_numpy)\u001b[0m\n\u001b[0;32m     17\u001b[0m vals_sub \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals_sub, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)    \n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_numpy:\n\u001b[1;32m---> 20\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mvals_sub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m#detach removes gradients (bad)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m cnn\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals_sub\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "#@title Get Modis CNN predictions\n",
    "def predict(cnn, x, as_numpy=False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cnn.eval()\n",
    "    x = x.type(torch.FloatTensor)\n",
    "    \n",
    "    \n",
    "    vals_sub = []\n",
    "    \n",
    "    x = TensorDataset(x)\n",
    "    sub_loader = DataLoader(x, batch_size=5000)\n",
    "    with torch.no_grad():\n",
    "        for images in sub_loader:\n",
    "            images = images[0].to(device)\n",
    "            vals_sub.append(cnn(images).cpu().numpy())\n",
    "            \n",
    "    vals_sub = np.concatenate(vals_sub, axis = 0)    \n",
    "    \n",
    "    if as_numpy:\n",
    "        output = vals_sub.flatten().cpu().detach().numpy() #detach removes gradients (bad)\n",
    "        \n",
    "    cnn.train()\n",
    "    return vals_sub.squeeze()\n",
    "\n",
    "# cnn_preds = predict(modis_net.cuda(), torch.Tensor(modis_ds).cuda(), as_numpy=True)\n",
    "\n",
    "modis_preds = predict(modis_net, torch.Tensor(modis_ordered), as_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KTiEyMx1oMO"
   },
   "source": [
    "### Sentinel Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded min -57.906 loaded max 18.57\n"
     ]
    }
   ],
   "source": [
    "sent_sub = np.load(rt_path + \"sent_pp_sub1\"+ DATE +\".npy\") \n",
    "sent_sub = minmaxscaler(sent_sub, [-57.906, 18.57])\n",
    "sent_sub = sent_sub.reshape(-1, 1, 41, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "id": "MT1jdBoFf7gF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 11 11\n",
      "c1 dim: 35\n",
      "mp0 dim: 33\n",
      "c2 dim: 27\n",
      "mp1 dim: 25\n",
      "c3 dim: 19\n",
      "c3_ dim: 13\n",
      "c3__ dim: 13\n",
      "mp2 dim: 11\n",
      "flattened_dim 968\n"
     ]
    }
   ],
   "source": [
    "#@title Load Sentinel CNN\n",
    "net_kwargs = {'cdim1': 32,\n",
    "              'cdim2': 18,\n",
    "              'cdim3': 8,\n",
    "              'kernel_sz': 7,\n",
    "              'dropout': 0.13,\n",
    "              'ldim': 16}\n",
    "\n",
    "sent_net = SentNet(**net_kwargs)\n",
    "sent_net.load_state_dict(torch.load(SENTINEL_CNN_PATH))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "_ = sent_net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1644952243810,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "4Mj8YGW-p1LJ",
    "outputId": "75e9cfe3-fdd0-437f-a9d4-6a8bbf650218"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.03 GiB (GPU 0; 8.00 GiB total capacity; 3.29 GiB already allocated; 2.14 GiB free; 3.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#@title Get Sentinel CNN predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sent_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_sub\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(cnn, x, as_numpy)\u001b[0m\n\u001b[0;32m      4\u001b[0m cnn\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_numpy:\n\u001b[0;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m#detach removes gradients (bad)\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\Python Scripts\\SnowComp\\realtime\\sentinel_cnn.py:69\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m#first layer\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# x = F.relu(x)\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.03 GiB (GPU 0; 8.00 GiB total capacity; 3.29 GiB already allocated; 2.14 GiB free; 3.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#@title Get Sentinel CNN predictions\n",
    "sent_preds = predict(sent_net, torch.Tensor(sent_sub), as_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sstp_6gNzBEM"
   },
   "outputs": [],
   "source": [
    "# TODO Matt: add in index to match MODIS predictions with dates/locations\n",
    "# TODO Matt: add in index to match Sentinel predictions with dates/locations\n",
    "\n",
    "def format_rf(df):\n",
    "    df['dos_2'] = df['dos'] ** 2\n",
    "    return df\n",
    "\n",
    "pred_df = format_rf(to_predict[to_predict['date'] == pd.to_datetime(predict_date)])\n",
    "\n",
    "modis_preds = np.random.randint(0, 20, len(pred_df)) # TODO delete\n",
    "sent_preds = np.random.randint(0, 20, len(pred_df))  # TODO delete\n",
    "\n",
    "pred_df['modis_pred'] = modis_preds\n",
    "pred_df['sent_pred'] = sent_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lt4eR6XPp1Gr"
   },
   "outputs": [],
   "source": [
    "#@title Get lm predictions\n",
    "def format_rf(df):\n",
    "    df['dos_2'] = df['dos'] ** 2\n",
    "    return df\n",
    "\n",
    "lm = joblib.load(LM_PATH)\n",
    "pred_df['snowpack'] = lm.predict(pred_df[['dos', 'dos_2', 'sent_pred', 'modis_pred']])\n",
    "pred_df.loc[pred_df['snowpack'] < 0, 'snowpack'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 4845,
     "status": "ok",
     "timestamp": 1644955075041,
     "user": {
      "displayName": "Isabella Scout Smythe",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06863503242150763563"
     },
     "user_tz": 300
    },
    "id": "iRRgvMNCp1I3"
   },
   "outputs": [],
   "source": [
    "#@title Write predictions\n",
    "def write_formatted_preds(preds_df, outpath):\n",
    "    preds_df = preds_df[['cell_id', 'date', 'snowpack']]\n",
    "    preds_df['date'] = preds_df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    submission = preds_df.pivot(index='cell_id', columns='date', values='snowpack')\\\n",
    "                        .reset_index()\\\n",
    "                        .sort_values('cell_id')\n",
    "    \n",
    "    assert sorted(submission.columns) == sorted(submission_format.columns)\n",
    "    assert sorted(submission['cell_id']) == sorted(submission_format['cell_id'])\n",
    "\n",
    "    submission.to_csv(PRED_PATH + '%s.csv' % outpath, index=False)\n",
    "\n",
    "\n",
    "out_df = pd.concat([to_predict, pred_df[to_predict.columns]])\\\n",
    "           .drop_duplicates(subset=['cell_id', 'date'], keep='last')\n",
    "x = write_formatted_preds(out_df[['cell_id', 'snowpack', 'date']], \n",
    "                      datetime.today().strftime('%Y%m%d_preds.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6zhLt88p1D8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMsMkHPdxeqL8J9FubA6pBd",
   "collapsed_sections": [
    "qGt-70QClelr"
   ],
   "name": "realtime.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
