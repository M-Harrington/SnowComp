{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b85fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "\n",
    "tqdm.pandas() \n",
    "\n",
    "rng = np.random.default_rng(342834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb53e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a901bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels helpers and processing\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def daynum_gen(date_time):\n",
    "    '''converts date time objects to filename'''\n",
    "    date_time = datetime.fromisoformat(date_time)\n",
    "    doy = date_time.timetuple().tm_yday\n",
    "    year = date_time.year\n",
    "    return str(year) + '{:03d}'.format(doy)\n",
    "\n",
    "# Get ordered elevation training data\n",
    "def add_elevation(order, modis):\n",
    "    order = pd.DataFrame({'modis_idx': order, 'order': [x for x in range(len(order))]})\n",
    "    order['station_id'] = order['modis_idx'].apply(lambda x: '-'.join(x.split('-')[:-1]))\n",
    "    order = order.merge(elev_order).sort_values('order')\n",
    "    ordered_elev = elevation[order['DEM_order'].to_list(), :, :]\n",
    "    dim = ordered_elev.shape\n",
    "\n",
    "    return np.concatenate([modis, ordered_elev.reshape(dim[0], 1, dim[1], dim[2])], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c49c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentinel Helpers\n",
    "def y_merger(x, y):\n",
    "    '''reattach y labels to sentinel'''\n",
    "    y = y.rename(columns={\"Unnamed: 0\":\"cell_id\"})\n",
    "    y = pivot_df(y, 'cell_id').dropna()\n",
    "    y['date']=y['date'].map(daynum_gen)\n",
    "\n",
    "    y['idx'] = y['cell_id'] + \"-\" + y['date']\n",
    "    y = y.set_index('idx')\n",
    "\n",
    "    x['idx'] = x['cell_id'] +\\\n",
    "         \"-\" +x['date_long'].astype(str)\n",
    "    x = x.set_index('idx')\n",
    "\n",
    "    return x.join(y['snowpack'])\n",
    "\n",
    "#preprocessing helpers\n",
    "def masker(x,y):\n",
    "#     return x , y\n",
    "    mask = np.all(x > -99, axis = (1,2))\n",
    "    print(mask.sum(), \"of\", len(mask))\n",
    "    \n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def minmaxscaler(x):\n",
    "    print(\"min\", round(x.min(),3), \"max\", round(x.max(),3))\n",
    "    x = (x - x.min())/(x.max() - x.min())\n",
    "                   \n",
    "    return x\n",
    "\n",
    "def reshaper(ds):\n",
    "    #readjust dimensions\n",
    "    dim0 = ds.shape[0]\n",
    "    dim1 = ds.shape[1]\n",
    "    dim2 = ds.shape[2]\n",
    "\n",
    "    return ds.reshape((dim0, 1, dim1, dim2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b9f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/\"\n",
    "\n",
    "#@title Original data\n",
    "metadata = pd.read_csv(DATA_PATH + 'ground_measures_metadata.csv')\n",
    "train_inp = pd.read_csv(DATA_PATH + 'ground_measures_train_features.csv')\n",
    "test_inp = pd.read_csv(DATA_PATH + 'ground_measures_test_features.csv')\n",
    "train_labels = pd.read_csv(DATA_PATH + 'train_labels.csv')\n",
    "grid_cells = gpd.read_file(DATA_PATH + 'grid_cells.geojson')\n",
    "submission_format = gpd.read_file(DATA_PATH + 'submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950d610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_19432\\662439698.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  cell_metadata['centroid'] = cell_metadata['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "#@title Get metadata for grid cells\n",
    "states = gpd.read_file('C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/states/')\\\n",
    "    .rename({'NAME': 'state'}, axis=1)\n",
    "states = states.to_crs('EPSG:4326')\n",
    "\n",
    "cell_metadata = gpd.sjoin(grid_cells, states[['geometry', 'state']])\\\n",
    "    .drop_duplicates(subset='cell_id')\\\n",
    "    .drop(['index_right'], axis=1)\n",
    "cell_metadata['centroid'] = cell_metadata['geometry'].centroid\n",
    "cell_metadata['longitude'] = cell_metadata['centroid'].x\n",
    "cell_metadata['latitude'] = cell_metadata['centroid'].y\n",
    "cell_metadata = cell_metadata[['cell_id', 'state', 'longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa35681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(df, actual='actual_snowpack', predicted='snowpack'):\n",
    "    return ((df[actual] - df[predicted]) ** 2).mean() ** 0.5\n",
    "\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_day_of_season(doy):\n",
    "    return doy + 365 - 335 if doy < 335 else doy - 335\n",
    "\n",
    "def add_time_cols(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['doy'] = df['date'].dt.dayofyear\n",
    "    df['dos'] = df['doy'].apply(get_day_of_season)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['season'] = df['year']\n",
    "    df.loc[df['doy'] < 335, 'season'] -= 1\n",
    "    return df\n",
    "\n",
    "def clean_train_test(df, id_col='station_id', metadata_df=None):\n",
    "    df = pivot_df(df, id_col)\n",
    "    if metadata_df is not None:\n",
    "        df = df.merge(metadata_df)\n",
    "    return add_time_cols(df)\n",
    "\n",
    "\n",
    "train = clean_train_test(train_inp.rename({'Unnamed: 0': 'station_id'}, axis=1),\n",
    "                         metadata_df=metadata)\n",
    "train2 = clean_train_test(train_labels, 'cell_id', cell_metadata).dropna()\n",
    "train_full = pd.concat([train2.rename({'cell_id': 'station_id'}, axis=1).assign(datatype='labels'),\n",
    "                        train.drop(['elevation_m', 'name'], axis=1).assign(datatype='ground')])\n",
    "\n",
    "test = clean_train_test(\n",
    "    test_inp.rename({'Unnamed: 0': 'station_id'}, axis=1), metadata_df=metadata)\\\n",
    "    .rename({'snowpack': 'actual_snowpack'}, axis=1).dropna()\\\n",
    "    .merge(train[['station_id', 'state']].drop_duplicates())\n",
    "\n",
    "to_predict = clean_train_test(submission_format.drop('geometry', axis=1), 'cell_id', cell_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0ff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "\n",
    "sentinel_trainfeat = np.load(sent_path + \"sent_pp_trainfeat.npy\")\n",
    "sentinel_testfeat = np.load(sent_path + \"sent_pp_testfeat.npy\")\n",
    "sentinel_ylabs = np.load(sent_path + \"sent_pp_ylabs.npy\")\n",
    "\n",
    "trainfeat_meta = pd.read_csv(sent_path + \"sent_trainfeat_meta.csv\")\n",
    "testfeat_meta = pd.read_csv(sent_path + \"sent_testfeat_meta.csv\")\n",
    "ylabs_meta = pd.read_csv(sent_path + \"sent_ylabs_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa9a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76159 of 76410\n",
      "105571 of 106760\n",
      "38618 of 38628\n",
      "min -57.906 max 18.57\n",
      "min -50.229 max 19.536\n",
      "min -27.488 max 14.445\n"
     ]
    }
   ],
   "source": [
    "sentinel_ylabs, ylabs_meta = masker(sentinel_ylabs, ylabs_meta)\n",
    "sentinel_trainfeat, trainfeat_meta = masker(sentinel_trainfeat, trainfeat_meta)\n",
    "sentinel_testfeat, testfeat_meta = masker(sentinel_testfeat, testfeat_meta)\n",
    "\n",
    "sentinel_ylabs = minmaxscaler(sentinel_ylabs)\n",
    "sentinel_trainfeat = minmaxscaler(sentinel_trainfeat)\n",
    "sentinel_testfeat = minmaxscaler(sentinel_testfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d02e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([sentinel_trainfeat, sentinel_ylabs])\n",
    "train_y = pd.concat([trainfeat_meta, ylabs_meta])\n",
    "train_y['date'] = pd.to_datetime(train_y['date'])\n",
    "train_y = train_y.merge(train_full.rename({'station_id': 'cell_id'}, axis=1)\\\n",
    "                                    [['cell_id', 'snowpack', 'date']])\n",
    "\n",
    "testfeat_meta['date'] = pd.to_datetime(testfeat_meta['date'])\n",
    "sentinel_ylab_test = testfeat_meta.merge(\n",
    "    test.rename({'station_id': 'cell_id', 'actual_snowpack': 'snowpack'}, axis=1)\\\n",
    "    [['cell_id', 'snowpack', 'date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3299089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sentinel_testfeat, sentinel_ylab_test\n",
    "# del sentinel_ylabs\n",
    "# del ylabs_meta\n",
    "# del sentinel_trainfeat\n",
    "# del trainfeat_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ec2f41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181730,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['snowpack'] .shape\n",
    "# ds_mean .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d24484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean = dataset.mean(axis = (1,2)).reshape(-1, 1)\n",
    "s_testfeat_mean = sentinel_testfeat.mean(axis = (1,2)).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a5b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.3759932733922"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(ds_mean, train_y['snowpack'])\n",
    "# reg.score(ds_mean, train_y['snowpack'])\n",
    "y_pred = reg.predict(ds_mean)\n",
    "((y_pred - train_y['snowpack'])**2).mean()**.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca1215a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>date</th>\n",
       "      <th>date_long</th>\n",
       "      <th>.geo</th>\n",
       "      <th>snowpack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDEC:SCT</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020007</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-122.7194819386...</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNOTEL:873_OR_SNTL</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020007</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-118.1519177111...</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNOTEL:327_CO_SNTL</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020007</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-107.5121235740...</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNOTEL:1058_CO_SNTL</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020007</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-106.5378278302...</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNOTEL:936_CO_SNTL</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020007</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-105.5934526545...</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38613</th>\n",
       "      <td>SNOTEL:523_OR_SNTL</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021180</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-118.1065686534...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38614</th>\n",
       "      <td>SNOTEL:1287_MT_SNTL</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021180</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-113.1224530419...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38615</th>\n",
       "      <td>SNOTEL:341_OR_SNTL</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021180</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-122.8548736239...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38616</th>\n",
       "      <td>SNOTEL:771_CA_SNTL</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021180</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-119.6003050789...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38617</th>\n",
       "      <td>CDEC:VVL</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>2021180</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-120.3060603799...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38618 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cell_id       date  date_long  \\\n",
       "0                 CDEC:SCT 2020-01-07    2020007   \n",
       "1       SNOTEL:873_OR_SNTL 2020-01-07    2020007   \n",
       "2       SNOTEL:327_CO_SNTL 2020-01-07    2020007   \n",
       "3      SNOTEL:1058_CO_SNTL 2020-01-07    2020007   \n",
       "4       SNOTEL:936_CO_SNTL 2020-01-07    2020007   \n",
       "...                    ...        ...        ...   \n",
       "38613   SNOTEL:523_OR_SNTL 2021-06-29    2021180   \n",
       "38614  SNOTEL:1287_MT_SNTL 2021-06-29    2021180   \n",
       "38615   SNOTEL:341_OR_SNTL 2021-06-29    2021180   \n",
       "38616   SNOTEL:771_CA_SNTL 2021-06-29    2021180   \n",
       "38617             CDEC:VVL 2021-06-29    2021180   \n",
       "\n",
       "                                                    .geo  snowpack  \n",
       "0      {\"type\":\"Point\",\"coordinates\":[-122.7194819386...      3.24  \n",
       "1      {\"type\":\"Point\",\"coordinates\":[-118.1519177111...      4.90  \n",
       "2      {\"type\":\"Point\",\"coordinates\":[-107.5121235740...     11.90  \n",
       "3      {\"type\":\"Point\",\"coordinates\":[-106.5378278302...      4.20  \n",
       "4      {\"type\":\"Point\",\"coordinates\":[-105.5934526545...      3.60  \n",
       "...                                                  ...       ...  \n",
       "38613  {\"type\":\"Point\",\"coordinates\":[-118.1065686534...      0.00  \n",
       "38614  {\"type\":\"Point\",\"coordinates\":[-113.1224530419...      0.00  \n",
       "38615  {\"type\":\"Point\",\"coordinates\":[-122.8548736239...      0.00  \n",
       "38616  {\"type\":\"Point\",\"coordinates\":[-119.6003050789...      0.00  \n",
       "38617  {\"type\":\"Point\",\"coordinates\":[-120.3060603799...      0.00  \n",
       "\n",
       "[38618 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinel_ylab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@title arrange data\n",
    "# mini_x = np.array(dataset.reshape(dataset.shape[0], 1, 41, 41))\n",
    "# mini_y = np.array(train_y['snowpack'])\n",
    "\n",
    "# test_x = np.array(sentinel_testfeat.reshape(sentinel_testfeat.shape[0], 1, 41, 41))\n",
    "# test_y = np.array(sentinel_ylab_test['snowpack'])\n",
    "\n",
    "# train_rows = len(mini_x)\n",
    "# test_rows = len(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
