{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f98b27",
   "metadata": {},
   "source": [
    "# Accessing Landsat 8 Collection 2 Level 2 data with the Planetary Computer STAC API\n",
    "\n",
    "The Landsat program has been imaging the Earth since 1972; it provides a comprehensive, continuous archive of the Earth's surface.\n",
    "\n",
    "This dataset represents the global archive of Level-2 Landsat 8 data from Landsat Collection 2. Images are stored in cloud-optimized GeoTIFF format.\n",
    "\n",
    "This notebook demonstrates the use of the Planetary Computer STAC API to query for Landsat 8 data.\n",
    "\n",
    "### Environment setup\n",
    "\n",
    "This notebook works with or without an API key, but you will be given more permissive access to the data with an API key. The Planetary Computer Hub is pre-configured to use your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import planetary_computer as pc\n",
    "\n",
    "# Set the environment variable PC_SDK_SUBSCRIPTION_KEY, or set it here.\n",
    "# The Hub sets PC_SDK_SUBSCRIPTION_KEY automatically.\n",
    "# pc.settings.set_subscription_key(<YOUR API Key>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aed4fc",
   "metadata": {},
   "source": [
    "Choose ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e24623",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [-122.27508544921875, 47.54687159892238],\n",
    "            [-121.96128845214844, 47.54687159892238],\n",
    "            [-121.96128845214844, 47.745787772920934],\n",
    "            [-122.27508544921875, 47.745787772920934],\n",
    "            [-122.27508544921875, 47.54687159892238],\n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e8926",
   "metadata": {},
   "source": [
    "We'll search all of 2020 for the least cloudy image of our area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd357c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_interest = \"2020-01-01/2020-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9783fa",
   "metadata": {},
   "source": [
    "### Search the collection and choose a scene to render\n",
    "\n",
    "Use pystac-client to perform the search over the Landsat 8 Collection 2 Level 2 collection, specifying we want results with less than 10% cloud cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[\"landsat-8-c2-l2\"],\n",
    "    intersects=area_of_interest,\n",
    "    datetime=time_of_interest,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}},\n",
    ")\n",
    "\n",
    "# Check how many items were returned\n",
    "items = list(search.get_items())\n",
    "print(f\"Returned {len(items)} Items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb697c4d",
   "metadata": {},
   "source": [
    "Returned 10 Items\n",
    "\n",
    "We can now work directly with the PySTAC Items returned by the API. Here we find the least cloudy of the bunch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0941bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = sorted(items, key=lambda item: eo.ext(item).cloud_cover)[0]\n",
    "\n",
    "print(\n",
    "    f\"Choosing {selected_item.id} from {selected_item.datetime.date()}\"\n",
    "    + f\" with {selected_item.properties['eo:cloud_cover']}% cloud cover\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a9c99",
   "metadata": {},
   "source": [
    "Choosing LC08_L2SP_046027_20200908_02_T1 from 2020-09-08 with 0.19% cloud cover\n",
    "\n",
    "### Choose bands from that scene for composite rendering\n",
    "\n",
    "Here we use the common name of STAC's eo extension to choose the red, green, and blue bands to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5692ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_asset_by_band_common_name(item, common_name):\n",
    "    for asset in item.assets.values():\n",
    "        asset_bands = eo.ext(asset).bands\n",
    "        if asset_bands and asset_bands[0].common_name == common_name:\n",
    "            return asset\n",
    "    raise KeyError(f\"{common_name} band not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981807cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_hrefs = [\n",
    "    find_asset_by_band_common_name(selected_item, \"red\").href,\n",
    "    find_asset_by_band_common_name(selected_item, \"green\").href,\n",
    "    find_asset_by_band_common_name(selected_item, \"blue\").href,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead082df",
   "metadata": {},
   "source": [
    "This HREF is a URL is the location of the asset data on Azure Blob Storage. In order to read the data, we'll need to retrieve a Shared Access Signature and supply it as a query parameter. These tokens are generated from the Planetary Computer Data Access API.\n",
    "\n",
    "We use the planetary-computer package to \"sign\" our asset HREF with a generated token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_hrefs = [pc.sign(asset_href) for asset_href in asset_hrefs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91ace7",
   "metadata": {},
   "source": [
    "### Render our AOI\n",
    "\n",
    "We can now use the HREFs to read our data in any tools that can retrieve data from URLs via HTTP GET operations.\n",
    "\n",
    "Here we use rasterio to render the image data over our area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio import features\n",
    "from rasterio import warp\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def read_band(href):\n",
    "    with rasterio.open(href) as ds:\n",
    "        aoi_bounds = features.bounds(area_of_interest)\n",
    "        warped_aoi_bounds = warp.transform_bounds(\"epsg:4326\", ds.crs, *aoi_bounds)\n",
    "        aoi_window = windows.from_bounds(transform=ds.transform, *warped_aoi_bounds)\n",
    "        return ds.read(1, window=aoi_window)\n",
    "\n",
    "\n",
    "bands = [read_band(href) for href in signed_hrefs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997ce8e",
   "metadata": {},
   "source": [
    "The code above reads the Cloud Optimized GeoTIFF data for each of the red, green, and blue bands. The band data is stored in separate images; we can use numpy's stack method to turn them into the equivalent of a multiband raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06876e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiband_data = np.stack(bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230c900",
   "metadata": {},
   "source": [
    "The data is in uint16, which PIL will not render as-is. This code rescales the image to values between 0-255, changes the data type and renders our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled = multiband_data.astype(float)\n",
    "min_value, max_value = rescaled.min(), rescaled.max()\n",
    "rescaled = ((rescaled - min_value) * 255) / (max_value - min_value)\n",
    "byte_data = rescaled.astype(\"ubyte\")\n",
    "Image.fromarray(np.transpose(byte_data, axes=[1, 2, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d5e7c",
   "metadata": {},
   "source": [
    "#### Render an NDVI image\n",
    "\n",
    "Landsat has several bands, and with them we can go beyond rendering RGB imagery; for example, the following code computes a Normalized Difference Vegetation Index (NDVI) using the near-infrared and red bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2785f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = read_band(\n",
    "    pc.sign(find_asset_by_band_common_name(selected_item, \"red\").href)\n",
    ").astype(float)\n",
    "\n",
    "nir = read_band(\n",
    "    pc.sign(find_asset_by_band_common_name(selected_item, \"nir08\").href)\n",
    ").astype(float)\n",
    "\n",
    "ndvi = (nir - r) / (nir + r)\n",
    "w = ndvi.shape[0]\n",
    "h = ndvi.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "dpi = 50\n",
    "fig = figure(figsize=(w / dpi, h / dpi), dpi=dpi, frameon=False)\n",
    "ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "\n",
    "plt.imshow(ndvi, cmap=\"viridis\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
