{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9c7785",
   "metadata": {},
   "source": [
    "# Pre-preprocessing Sentinel 1\n",
    "\n",
    "list of `cell_id, date, lat, lon` for downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c8cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geojson as gsn\n",
    "from pyproj import Proj\n",
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "\n",
    "import tempfile\n",
    "import wget\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccfe4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daynum_gen(date_time):\n",
    "    '''converts date time objects to filename'''\n",
    "    date_time = datetime.fromisoformat(date_time)\n",
    "    doy = date_time.timetuple().tm_yday\n",
    "    year = date_time.year\n",
    "    return str(year) + '{:03d}'.format(doy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f73da42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/ground_measures_train_features.csv\")\n",
    "test =pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/ground_measures_test_features.csv\")\n",
    "submission = pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/submission_format.csv\")\n",
    "train_y = pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/train_labels.csv\") \n",
    "metadata = pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/ground_measures_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54cc02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18130\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/grid_cells.geojson\"\n",
    "with open(path) as f:\n",
    "    gj = gsn.load(f)\n",
    "print(len(gj['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "566d6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = {} #cellid : centroid\n",
    "\n",
    "for cell in range(len(gj['features'])):\n",
    "    assert len(gj['features'][cell]['geometry']['coordinates'][0]) == 5 #coordinates have repeat on fifth, make sure this is universal\n",
    "    \n",
    "    cell_id =gj['features'][cell]['properties']['cell_id']\n",
    "    centroid = list(np.mean(\n",
    "        gj['features'][cell]['geometry']['coordinates'][0][0:4],\n",
    "        axis = 0)) #lazy centroid calculation\n",
    "    centroids[cell_id] = centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c52e4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cell ids, note Ts are correct, As are actual daynums \n",
    "path_id = \"C:/Users/Matt/Dropbox/SnowComp/cell_snow_idsT.pkl\"\n",
    "with open(path_id, 'rb') as handle:\n",
    "    cell_ids = pickle.load( handle)\n",
    "\n",
    "path_id = \"C:/Users/Matt/Dropbox/SnowComp/cell_snow_ids_trainfeat.pkl\"\n",
    "with open(path_id, 'rb') as handle:\n",
    "    cell_ids_train = pickle.load(handle)\n",
    "    \n",
    "path_id = \"C:/Users/Matt/Dropbox/SnowComp/cell_snow_ids_testfeat.pkl\"\n",
    "with open(path_id, 'rb') as handle:\n",
    "    cell_ids_test = pickle.load( handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02618246",
   "metadata": {},
   "source": [
    "## Train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfc6a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_loc_gen(dataframe, cell_ids = None, metadata= None, centroids=centroids):\n",
    "    #grab date/cell_id combos\n",
    "    dates = {}\n",
    "\n",
    "    #go through all rows, grab nonnull dates\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        dates[dataframe.iloc[i,0]] =list(\n",
    "            dataframe.iloc[i,1:][~dataframe.iloc[i,:].isnull()].index)#cell_id : [dates]\n",
    "\n",
    "    if metadata is not None:\n",
    "        dataframe = dataframe.rename({'Unnamed: 0': 'station_id'}, axis=1)\n",
    "        dataframe = dataframe.merge(metadata)\n",
    "        \n",
    "        #get coordinates into correct format\n",
    "        a= dataframe.set_index(\"station_id\")\n",
    "        a= a[['latitude','longitude']]\n",
    "        centroids = {}\n",
    "        \n",
    "        for i in range(a.shape[0]):\n",
    "            row = a.iloc[i,:]\n",
    "            centroids[row.name]= [row[1],row[0]]\n",
    "            \n",
    "        \n",
    "    date_locs = []\n",
    "\n",
    "    # create a numpy array date_locs (cell_id, date, lat, lon)\n",
    "    counter = 0 \n",
    "    for cell, date_list in tqdm(dates.items()):\n",
    "        for date in date_list:        \n",
    "            date_locs.append([cell, date, centroids[cell][1], centroids[cell][0]])\n",
    "\n",
    "            counter += 1\n",
    "    print(\"total squares:\", counter)    \n",
    "    \n",
    "    date_locs = pd.DataFrame(date_locs, columns = ['cell_id', 'date', 'lat', 'lon'])\n",
    "        \n",
    "    date_locs['date_long']=date_locs['date'].map(daynum_gen)\n",
    "\n",
    "#     sorter = [idx +\"-\" +date for  idx, date  in cell_ids]\n",
    "#     date_locs['idx'] = date_locs['cell_id'] +\"-\"+date_locs['date_long']\n",
    "#     date_locs = date_locs.set_index('idx')\n",
    "#     date_locs = date_locs.loc[sorter]    \n",
    "#     date_locs.reset_index(inplace=True, drop=True)\n",
    "#     date_locs.drop(\"date_long\", inplace =True, axis=1)\n",
    "    \n",
    "    return date_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf9de99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e60dd6a344c319d45ccf606f2e944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total squares: 91490\n",
      "(91490, 5)\n",
      "after (76410, 5)\n"
     ]
    }
   ],
   "source": [
    "date_locs = date_loc_gen(train_y, cell_ids)\n",
    "date_locs = date_locs.sort_values(\"date_long\")\n",
    "print(date_locs.shape)\n",
    "\n",
    "# April 3, 2014 is 2014093, sentinel's launch date\n",
    "# But November 1st, 2014 is 2014305, first day of data (-30d)\n",
    "first_day = 2014305\n",
    "date_locs = date_locs[date_locs.date_long >= str(first_day)]\n",
    "\n",
    "print(\"after\", date_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ddab1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "date_locs.to_csv(sent_path + \"ylabs_dateloc.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4622705",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = date_locs.date.unique()\n",
    "pd.Series(unique_dates, name = \"date\").to_csv(sent_path + \"date_list_ylabs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "033b07b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# date_locs\n",
    "# pd.Series(unique_dates, name = \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6e145",
   "metadata": {},
   "source": [
    "## Train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96759126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9c54a420de4dbbbd9945db72a82812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total squares: 144015\n"
     ]
    }
   ],
   "source": [
    "date_loc_tf = date_loc_gen(train_feat, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34c1ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144015, 5)\n",
      "after (106760, 5)\n"
     ]
    }
   ],
   "source": [
    "date_loc_tf  = date_loc_tf .sort_values(\"date_long\")\n",
    "print(date_loc_tf.shape)\n",
    "\n",
    "# April 3, 2014 is 2014093, sentinel's launch date\n",
    "# But November 1st, 2014 is 2014305, first day of data (-30d)\n",
    "first_day = 2014305\n",
    "date_loc_tf  = date_loc_tf[date_loc_tf.date_long >= str(first_day)]\n",
    "\n",
    "print(\"after\", date_loc_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54218574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "date_loc_tf.to_csv(sent_path + \"trainfeat_dateloc.csv\", index= False)\n",
    "\n",
    "unique_dates = date_loc_tf.date.unique()\n",
    "pd.Series(unique_dates, name = \"date\").to_csv(sent_path + \"date_list_trainfeat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63063e96",
   "metadata": {},
   "source": [
    "## Test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7cee7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c9823ef5454b6797067365c2d12799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total squares: 38628\n",
      "(38628, 5)\n",
      "after (38628, 5)\n"
     ]
    }
   ],
   "source": [
    "date_loc_test = date_loc_gen(test, metadata=metadata)\n",
    "\n",
    "date_loc_test  = date_loc_test.sort_values(\"date_long\")\n",
    "print(date_loc_test.shape)\n",
    "\n",
    "#note no filtering is needed because these are later dates\n",
    "\n",
    "sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "date_loc_test.to_csv(sent_path + \"testfeat_dateloc.csv\", index= False)\n",
    "\n",
    "unique_dates = date_loc_test.date.unique()\n",
    "pd.Series(unique_dates, name = \"date\").to_csv(sent_path + \"date_list_testfeat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13049da6",
   "metadata": {},
   "source": [
    "## Submission dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8306d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9066, 58)\n",
      "(4533, 58)\n",
      "(4533, 58)\n"
     ]
    }
   ],
   "source": [
    "half = int(submission.shape[0]/2)\n",
    "print(submission.shape)\n",
    "print(submission.iloc[0:half].shape)\n",
    "print(submission.iloc[half:].shape)\n",
    "sub_all = [submission.iloc[0:half], submission.iloc[half:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbd58b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284c9a16f329483ea68b032ab6f572f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total squares: 258381\n",
      "(258381, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a00266f5034c5d908ca616a342843f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total squares: 258381\n",
      "(258381, 5)\n"
     ]
    }
   ],
   "source": [
    "for i, ds in enumerate(sub_all):\n",
    "    date_loc_sub = date_loc_gen(ds)\n",
    "\n",
    "    date_loc_sub  = date_loc_sub.sort_values(\"date_long\")\n",
    "    print(date_loc_sub.shape)\n",
    "\n",
    "    #note no filtering is needed because these are later dates\n",
    "\n",
    "    sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "    date_loc_sub.to_csv(sent_path + \"sub_dateloc\"+ \"{}of{}\".format(i+1,len(sub_all))+\n",
    "                        \".csv\", index= False)\n",
    " \n",
    "    \n",
    "#this will be the same for all data points    \n",
    "unique_dates = date_loc_sub.date.unique()\n",
    "pd.Series(unique_dates, name = \"date\").to_csv(sent_path + \"date_list_sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
