{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9b5b40b",
   "metadata": {
    "id": "f9b5b40b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf6eca",
   "metadata": {
    "id": "0ebf6eca"
   },
   "source": [
    "### Load in (correct) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fc9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/Matt/Dropbox/SnowComp/\"\n",
    "path1 = base_path+\"ModisSnowImagesT.npy\"\n",
    "path2 = base_path+\"ModisSnowImagesA.npy\"\n",
    "path3 = base_path+\"ModisSnowImages_subT.npy\"\n",
    "path4 = base_path+\"ModisSnowImages_subA.npy\"\n",
    "\n",
    "train_dataT = np.load(path1)\n",
    "train_dataA = np.load(path2)\n",
    "# sub_dataT = np.load(path3) #be careful about memory, this is about 25-30 gigs ram\n",
    "# sub_dataA = np.load(path4)\n",
    "\n",
    "#load cell ids, note Ts are correct, As are actual daynums \n",
    "path_id = \"C:/Users/Matt/Dropbox/SnowComp/cell_snow_idsT.pkl\"\n",
    "with open(path_id, 'rb') as handle:\n",
    "    cell_ids = pickle.load( handle)\n",
    "    \n",
    "train_y = pd.read_csv(\"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b947c93d",
   "metadata": {
    "id": "b947c93d"
   },
   "outputs": [],
   "source": [
    "#labels helpers and processing\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def daynum_gen(date_time):\n",
    "    '''converts date time objects to filename'''\n",
    "    date_time = datetime.fromisoformat(date_time)\n",
    "    doy = date_time.timetuple().tm_yday\n",
    "    year = date_time.year\n",
    "    return str(year) + '{:03d}'.format(doy)\n",
    "\n",
    "train_y = pivot_df(train_y, 'cell_id').dropna()\n",
    "train_y['date']=train_y['date'].map(daynum_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edac2dc0",
   "metadata": {
    "id": "edac2dc0"
   },
   "outputs": [],
   "source": [
    "#sort train_y so it has correct order before stripping labels\n",
    "train_y['idx'] = train_y['cell_id'] +\"-\"+train_y['date']\n",
    "sorter = [idx +\"-\" +date for  idx, date  in cell_ids]\n",
    "train_y = train_y.set_index('idx')\n",
    "train_y = train_y.loc[sorter]\n",
    "\n",
    "#combine Aqua and Terra DSs\n",
    "dataset = np.concatenate((train_dataT[:,0:1,:,:],train_dataA[:,0:1,:,:]), axis = 1)\n",
    "# dataset = np.concatenate((train_dataT,train_dataA), axis = 1)\n",
    "\n",
    "# #delete problematic columns\n",
    "# dataset = np.delete(dataset, 3, 1) \n",
    "# dataset = np.delete(dataset, 9, 1)\n",
    "\n",
    "dataset= dataset/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xzy-yKA8089p",
   "metadata": {
    "id": "xzy-yKA8089p"
   },
   "source": [
    "# Basic pytorch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4hSy2cPa0w1L",
   "metadata": {
    "cellView": "form",
    "id": "4hSy2cPa0w1L"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Y6LVO6sr0cNn",
   "metadata": {
    "id": "Y6LVO6sr0cNn"
   },
   "outputs": [],
   "source": [
    "# Do categorical preds to start (change)\n",
    "train_y['cat'] = train_y['snowpack'].apply(lambda x: 1 if x > 15 else 0)\n",
    "# dataset.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "_ZFymFE0nMRh",
   "metadata": {
    "cellView": "form",
    "id": "_ZFymFE0nMRh"
   },
   "outputs": [],
   "source": [
    "#@title Define simple CNN\n",
    "# From: https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html\n",
    "# Also used: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "START_D = 2\n",
    "START_HW = 21\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def _conv_calc(self, in_dim, pad, stride, k):\n",
    "        out = int(np.floor((in_dim + 2 * pad - (k - 1) - 1) / stride + 1))\n",
    "        return out\n",
    "\n",
    "    def __init__(self, cdim1, cdim2, kernel_sz, dropout,\n",
    "                 ldim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(2, cdim1, kernel_sz, 1)\n",
    "        c1_dim = self._conv_calc(START_HW, 0, 1, kernel_sz)\n",
    "        print('c1 dim:', c1_dim)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(cdim1, cdim2, kernel_sz, 1)\n",
    "        c2_dim = self._conv_calc(c1_dim, 0, 1, kernel_sz)\n",
    "        print('c2 dim:', c2_dim)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        mp1_dim = self._conv_calc(c2_dim, 0, 2, 2)\n",
    "        # print('mp1 dim:', mp1_dim)\n",
    "        \n",
    "        # self.conv3 = nn.Conv2d(cdim2, cdim2, kernel_sz, 1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        self.dropout2 = nn.Dropout2d(2 * dropout)\n",
    "\n",
    "        flattened_dim = cdim2 * mp1_dim * mp1_dim\n",
    "        print(flattened_dim)\n",
    "        self.fc1 = nn.Linear(flattened_dim, ldim)\n",
    "        # self.fc1 = nn.Linear(8192, ldim)\n",
    "        self.fc2 = nn.Linear(ldim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # x = self.dropout1(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = F.relu(x)\n",
    "\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vH2t7GaryngE",
   "metadata": {
    "cellView": "form",
    "id": "vH2t7GaryngE"
   },
   "outputs": [],
   "source": [
    "#@title Helpers to get predictions and accuracy\n",
    "def predict(cnn, x, as_numpy=False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cnn.eval()\n",
    "    x =x.type(torch.FloatTensor).to(device)\n",
    "    output = cnn(x)\n",
    "    if as_numpy:\n",
    "        output = output.flatten().cpu().detach().numpy() #detach removes gradients (bad)\n",
    "        \n",
    "    cnn.train()\n",
    "    return output.squeeze()\n",
    "\n",
    "def get_accuracy(cnn, x, y):\n",
    "#     y = torch.from_numpy(y).to(device)\n",
    "    outputs = predict(cnn, x,as_numpy = True)\n",
    "    \n",
    "#     print(y.shape, outputs.shape)\n",
    "    loss = ((y-outputs)**2).mean()\n",
    "    return round(loss.item(), 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CzIiQX4hnMOL",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzIiQX4hnMOL",
    "outputId": "8aeeac04-d3f3-49a8-d991-7c26fe94f061"
   },
   "outputs": [],
   "source": [
    "#@title Test run\n",
    "# my_nn = Net(cdim1=8, cdim2=8, kernel_sz=3, dropout=0.25, ldim=8)\n",
    "# optimizer = optim.Adam(my_nn.parameters(), lr=0.1)\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# test_im = torch.from_numpy(dataset[0]).reshape(1, 14, 21, 21)\n",
    "# result = my_nn(test_im.type(torch.FloatTensor))\n",
    "# result.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b07fcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2496195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title split training and testing\n",
    "\n",
    "mask = np.random.rand(len(dataset)) < 0.9\n",
    "training_data = dataset[mask]\n",
    "testing_data = dataset[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "j9xCBXI-nMK9",
   "metadata": {
    "cellView": "form",
    "id": "j9xCBXI-nMK9"
   },
   "outputs": [],
   "source": [
    "#@title Get data loaders\n",
    "# train_dataset = TensorDataset(torch.Tensor(dataset),\n",
    "#                               torch.Tensor(train_y['snowpack']))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "# mini_x, mini_y = np.array(dataset)[:2,], np.array(train_y['snowpack'])[:2,]\n",
    "\n",
    "test_x, test_y = np.array(dataset)[~mask], np.array(train_y['snowpack'])[~mask]\n",
    "test_x, test_y = torch.Tensor(test_x), torch.Tensor(test_y)\n",
    "\n",
    "\n",
    "mini_x, mini_y = np.array(dataset)[mask], np.array(train_y['snowpack'])[mask]\n",
    "mini_x, mini_y = torch.Tensor(mini_x), torch.Tensor(mini_y)\n",
    "\n",
    "mini_dataset = TensorDataset(mini_x,\n",
    "                              mini_y)\n",
    "mini_loader = DataLoader(mini_dataset, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GwEGyBD2nMIR",
   "metadata": {
    "cellView": "form",
    "id": "GwEGyBD2nMIR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#@title Setup net\n",
    "my_nn = Net(cdim1=32, cdim2=24, kernel_sz=3, dropout=0, ldim=14)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_nn.to(device)\n",
    "\n",
    "optimizer = optim.Adam(my_nn.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "writer = SummaryWriter('runs/cnn_full')\n",
    "write_index = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rZKIBpS5nMAZ",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZKIBpS5nMAZ",
    "outputId": "40e82096-4e7c-42b9-9b24-2e38d7fb1bec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200 complete 285.473907 114019.33647346497\n",
      "1 / 200 complete 280.01358 106594.94483876228\n",
      "2 / 200 complete 273.783112 103227.64334869385\n",
      "3 / 200 complete 270.166626 100228.558994174\n",
      "4 / 200 complete 254.996521 95978.62303519249\n",
      "5 / 200 complete 253.728577 91759.81201410294\n",
      "6 / 200 complete 239.712631 88855.48102980852\n",
      "7 / 200 complete 240.309174 86566.37278831005\n",
      "8 / 200 complete 239.058365 85393.29599505663\n",
      "9 / 200 complete 238.335922 84956.74796444178\n",
      "10 / 200 complete 237.549301 84663.40807497501\n",
      "11 / 200 complete 233.613419 84511.97795438766\n",
      "12 / 200 complete 238.518204 84447.63498139381\n",
      "13 / 200 complete 232.480713 82999.59153664112\n",
      "14 / 200 complete 230.564407 82575.09020650387\n",
      "15 / 200 complete 230.418518 82049.74405807257\n",
      "16 / 200 complete 226.537979 81850.76433259249\n",
      "17 / 200 complete 230.017746 81745.8089197874\n",
      "18 / 200 complete 225.154602 81389.58358746767\n",
      "19 / 200 complete 227.541168 81256.26586401463\n",
      "20 / 200 complete 223.170029 80931.53489857912\n",
      "21 / 200 complete 224.187927 80751.92800199986\n",
      "22 / 200 complete 222.558472 80689.985024333\n",
      "23 / 200 complete 222.20372 80347.95366376638\n",
      "24 / 200 complete 221.073334 80056.93041741848\n",
      "25 / 200 complete 223.763779 79962.24766737223\n",
      "26 / 200 complete 220.072906 79881.27667921782\n",
      "27 / 200 complete 219.983871 79584.9003047347\n",
      "28 / 200 complete 219.362854 79548.09953713417\n",
      "29 / 200 complete 219.228683 79530.11394572258\n",
      "30 / 200 complete 219.201508 79216.44173908234\n",
      "31 / 200 complete 223.243561 79304.3708177805\n",
      "32 / 200 complete 218.517624 79402.50634753704\n",
      "33 / 200 complete 218.279083 78905.4869478941\n",
      "34 / 200 complete 224.347443 79075.37935483456\n",
      "35 / 200 complete 217.962708 79288.45590937138\n",
      "36 / 200 complete 217.680908 78672.65581202507\n",
      "37 / 200 complete 224.121689 78717.33364927769\n",
      "38 / 200 complete 217.126419 79333.9377926588\n",
      "39 / 200 complete 225.132584 79111.71246349812\n",
      "40 / 200 complete 226.839874 78748.09051561356\n",
      "41 / 200 complete 217.868637 79235.96382570267\n",
      "42 / 200 complete 215.811615 78106.83280420303\n",
      "43 / 200 complete 217.167053 78466.5352742672\n",
      "44 / 200 complete 215.445251 77863.28050899506\n",
      "45 / 200 complete 216.595734 78198.14311408997\n",
      "46 / 200 complete 215.092377 77725.79526269436\n",
      "47 / 200 complete 216.481277 78127.22198212147\n",
      "48 / 200 complete 214.739471 77484.36837506294\n",
      "49 / 200 complete 216.282791 77683.6459031105\n",
      "50 / 200 complete 214.460266 77385.96519756317\n",
      "51 / 200 complete 216.17244 77563.6093018055\n",
      "52 / 200 complete 214.99292 76948.14029705524\n",
      "53 / 200 complete 215.03212 77510.89565551281\n",
      "54 / 200 complete 213.788651 76711.15785825253\n",
      "55 / 200 complete 216.898193 77521.57921850681\n",
      "56 / 200 complete 213.304901 76879.64608418941\n",
      "57 / 200 complete 218.947586 77191.35229551792\n",
      "58 / 200 complete 216.06694 76924.31059098244\n",
      "59 / 200 complete 214.555313 77101.52802968025\n",
      "60 / 200 complete 212.475677 76430.19312489033\n",
      "61 / 200 complete 219.611496 76911.8843151331\n",
      "62 / 200 complete 214.960281 76346.7054772377\n",
      "63 / 200 complete 222.4944 76657.43947339058\n",
      "64 / 200 complete 214.995544 76378.02197146416\n",
      "65 / 200 complete 215.08316 77004.71313726902\n",
      "66 / 200 complete 213.447678 75997.53259766102\n",
      "67 / 200 complete 211.977524 76820.05613589287\n",
      "68 / 200 complete 212.157242 76074.60070228577\n",
      "69 / 200 complete 228.779785 75956.64036035538\n",
      "70 / 200 complete 210.891068 76024.46057534218\n",
      "71 / 200 complete 212.396149 76320.98968076706\n",
      "72 / 200 complete 212.053543 75422.71092438698\n",
      "73 / 200 complete 215.544235 76566.40688991547\n",
      "74 / 200 complete 210.353912 75482.69846999645\n",
      "75 / 200 complete 212.0867 76156.66725897789\n",
      "76 / 200 complete 210.317978 75332.98091042042\n",
      "77 / 200 complete 212.883423 75661.52819144726\n",
      "78 / 200 complete 209.745331 75502.12852692604\n",
      "79 / 200 complete 222.791031 75592.77052295208\n",
      "80 / 200 complete 210.462112 78611.2988575697\n",
      "81 / 200 complete 209.237274 75683.37732243538\n",
      "82 / 200 complete 208.543686 75074.44021701813\n",
      "83 / 200 complete 208.867523 75097.4550921917\n",
      "84 / 200 complete 208.68573 74956.42874741554\n",
      "85 / 200 complete 208.871704 74549.34059226513\n",
      "86 / 200 complete 209.170227 74845.24354290962\n",
      "87 / 200 complete 208.187607 74706.22701883316\n",
      "88 / 200 complete 209.222687 74541.52583324909\n",
      "89 / 200 complete 209.411758 74795.09081435204\n",
      "90 / 200 complete 210.073151 74434.57371342182\n",
      "91 / 200 complete 210.63443 74266.95342087746\n",
      "92 / 200 complete 210.197144 74183.07551121712\n",
      "93 / 200 complete 210.656769 74111.66831851006\n",
      "94 / 200 complete 209.158188 74182.55862283707\n",
      "95 / 200 complete 209.277969 73978.51575040817\n",
      "96 / 200 complete 211.632019 74008.70395839214\n",
      "97 / 200 complete 209.391739 74057.43836963177\n",
      "98 / 200 complete 205.782516 73907.53887414932\n",
      "99 / 200 complete 212.081085 73832.06881833076\n",
      "100 / 200 complete 207.541946 73644.60788667202\n",
      "101 / 200 complete 204.673141 73696.85088503361\n",
      "102 / 200 complete 218.967606 73615.61194729805\n",
      "103 / 200 complete 206.414825 76362.68056559563\n",
      "104 / 200 complete 205.056152 73734.7821598053\n",
      "105 / 200 complete 205.753265 73479.1504818201\n",
      "106 / 200 complete 205.179031 73323.17104279995\n",
      "107 / 200 complete 204.591446 73280.70866751671\n",
      "108 / 200 complete 204.141037 73255.10345947742\n",
      "109 / 200 complete 204.061584 73149.06123483181\n",
      "110 / 200 complete 203.390091 73087.43431293964\n",
      "111 / 200 complete 205.019714 72967.18864905834\n",
      "112 / 200 complete 208.133652 72805.1353417635\n",
      "113 / 200 complete 204.853836 72926.84106445312\n",
      "114 / 200 complete 205.277237 72719.3773342371\n",
      "115 / 200 complete 204.556824 72559.82088804245\n",
      "116 / 200 complete 205.027527 72452.76204717159\n",
      "117 / 200 complete 204.073929 72452.21228122711\n",
      "118 / 200 complete 204.326904 72328.59470164776\n",
      "119 / 200 complete 204.005356 72487.59321343899\n",
      "120 / 200 complete 202.963409 72385.05782842636\n",
      "121 / 200 complete 203.669586 72249.57053053379\n",
      "122 / 200 complete 203.141083 72262.58100485802\n",
      "123 / 200 complete 201.261948 72350.82995092869\n",
      "124 / 200 complete 202.914017 72099.47354757786\n",
      "125 / 200 complete 202.27623 72194.00411331654\n",
      "126 / 200 complete 202.41124 72050.06671595573\n",
      "127 / 200 complete 202.282364 72072.97372412682\n",
      "128 / 200 complete 201.977509 71987.37433075905\n",
      "129 / 200 complete 202.230606 71963.81700026989\n",
      "130 / 200 complete 201.619476 71943.98230063915\n",
      "131 / 200 complete 201.12532 71926.48245537281\n",
      "132 / 200 complete 198.878845 71869.81956410408\n",
      "133 / 200 complete 198.786667 71851.7389883995\n",
      "134 / 200 complete 200.601379 71723.52775681019\n",
      "135 / 200 complete 200.199142 71590.21106815338\n",
      "136 / 200 complete 199.79863 71454.48553180695\n",
      "137 / 200 complete 199.979141 71476.36658668518\n",
      "138 / 200 complete 200.14563 71400.90004253387\n",
      "139 / 200 complete 199.717804 71395.66191387177\n",
      "140 / 200 complete 199.898453 71345.85174632072\n",
      "141 / 200 complete 198.00206 71268.89691829681\n",
      "142 / 200 complete 198.384964 71255.6310172081\n",
      "143 / 200 complete 198.301941 71193.34339308739\n",
      "144 / 200 complete 197.920029 71217.91721367836\n",
      "145 / 200 complete 197.677872 71198.86765623093\n",
      "146 / 200 complete 197.44458 71240.01942205429\n",
      "147 / 200 complete 197.326569 71312.44702076912\n",
      "148 / 200 complete 196.402863 71299.92678451538\n",
      "149 / 200 complete 197.355377 71293.68172359467\n",
      "150 / 200 complete 197.172394 71079.93320965767\n",
      "151 / 200 complete 197.253387 71047.20904636383\n",
      "152 / 200 complete 196.517517 70964.16258525848\n",
      "153 / 200 complete 197.550262 70902.12934279442\n",
      "154 / 200 complete 199.65683 70914.31280779839\n",
      "155 / 200 complete 200.977509 71128.05180120468\n",
      "156 / 200 complete 201.301392 70972.61645007133\n",
      "157 / 200 complete 195.498367 70898.02902245522\n",
      "158 / 200 complete 195.254807 70560.43994617462\n",
      "159 / 200 complete 203.051941 70500.63829874992\n",
      "160 / 200 complete 200.678543 70707.84211683273\n",
      "161 / 200 complete 194.586578 70710.44803404808\n",
      "162 / 200 complete 194.771759 70485.98620438576\n",
      "163 / 200 complete 194.352386 70350.32174181938\n",
      "164 / 200 complete 194.500076 70275.59383964539\n",
      "165 / 200 complete 204.129089 70062.66682863235\n",
      "166 / 200 complete 193.818756 70300.82886075974\n",
      "167 / 200 complete 194.335907 70229.87015032768\n",
      "168 / 200 complete 194.073914 70045.46798086166\n",
      "169 / 200 complete 193.390472 70530.7503478527\n",
      "170 / 200 complete 193.339157 70245.86997509003\n",
      "171 / 200 complete 192.961182 70414.24444818497\n",
      "172 / 200 complete 192.92189 70198.60495662689\n",
      "173 / 200 complete 193.025452 70536.52465772629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 / 200 complete 192.674652 70310.9325158596\n",
      "175 / 200 complete 202.707886 70280.02042293549\n",
      "176 / 200 complete 192.248337 69962.40660023689\n",
      "177 / 200 complete 192.545242 70107.09295225143\n",
      "178 / 200 complete 192.645004 69972.55846977234\n",
      "179 / 200 complete 192.143234 70043.43641638756\n",
      "180 / 200 complete 192.417969 69826.37281036377\n",
      "181 / 200 complete 191.899811 69915.9555490017\n",
      "182 / 200 complete 191.980209 69789.33359646797\n",
      "183 / 200 complete 191.848267 69881.27257442474\n",
      "184 / 200 complete 191.8694 69779.55110478401\n",
      "185 / 200 complete 192.159576 69887.07304692268\n",
      "186 / 200 complete 191.718948 69883.86778998375\n",
      "187 / 200 complete 191.701035 69680.87061047554\n",
      "188 / 200 complete 191.884537 69914.88537836075\n",
      "189 / 200 complete 191.636063 69649.57746076584\n",
      "190 / 200 complete 191.720642 69602.39973449707\n",
      "191 / 200 complete 191.358688 69582.7741010189\n",
      "192 / 200 complete 191.665588 69539.42324185371\n",
      "193 / 200 complete 191.025406 69358.09476852417\n",
      "194 / 200 complete 191.16188 69372.91123652458\n",
      "195 / 200 complete 190.543472 69372.3970580101\n",
      "196 / 200 complete 190.994934 69099.71297717094\n",
      "197 / 200 complete 190.787796 69147.02860569954\n",
      "198 / 200 complete 190.613663 69056.90070605278\n",
      "199 / 200 complete 190.20787 68937.26556038857\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 199\n",
    "\n",
    "#@title Run net\n",
    "for epoch in range(N_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(mini_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = my_nn(inputs).squeeze()\n",
    "#         print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         for name, param in my_nn.named_parameters():\n",
    "#             print(name, param.grad.abs().sum())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Loss/train', running_loss , write_index)\n",
    "        write_index += 1\n",
    "\n",
    "    val_acc = get_accuracy(my_nn, mini_x, mini_y)\n",
    "    writer.add_scalar('Acc/val', val_acc, write_index)\n",
    "    print(epoch, '/', N_EPOCHS, 'complete', val_acc, running_loss )\n",
    "\n",
    "    #calculate test loss.\n",
    "    \n",
    "    \n",
    "    \n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0c97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e00e48",
   "metadata": {},
   "source": [
    "### Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b96b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_nn = my_nn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de3e80bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.7583],\n",
       "        [-1.7966],\n",
       "        [ 8.3834],\n",
       "        ...,\n",
       "        [ 9.8723],\n",
       "        [10.8684],\n",
       "        [11.0105]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn = my_nn.to('cpu')\n",
    "vals = my_nn(mini_x)\n",
    "\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7fd314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22.5000,  0.0000, 16.7000,  ..., 41.5000,  2.9000, 11.5000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1342dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.79288"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((vals.detach().numpy().flatten()  - mini_y.numpy())**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb12a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.758299 ],\n",
       "       [-1.7966311],\n",
       "       [ 8.383375 ],\n",
       "       ...,\n",
       "       [ 9.872345 ],\n",
       "       [10.868359 ],\n",
       "       [11.010481 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c4033",
   "metadata": {},
   "source": [
    "## Things to check\n",
    "\n",
    "1. Accuracy measures are right\n",
    "2. Check missing value\n",
    "\n",
    "### TODO:\n",
    "- Add test set/cv\n",
    "- Batchnorm?\n",
    "- CNN benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b9c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
