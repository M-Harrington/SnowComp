{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c0daff",
   "metadata": {},
   "source": [
    "# CNN for Sentinel Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fed0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "\n",
    "tqdm.pandas() \n",
    "\n",
    "rng = np.random.default_rng(342834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d257ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels helpers and processing\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def daynum_gen(date_time):\n",
    "    '''converts date time objects to filename'''\n",
    "    date_time = datetime.fromisoformat(date_time)\n",
    "    doy = date_time.timetuple().tm_yday\n",
    "    year = date_time.year\n",
    "    return str(year) + '{:03d}'.format(doy)\n",
    "\n",
    "# Get ordered elevation training data\n",
    "def add_elevation(order, modis):\n",
    "    order = pd.DataFrame({'modis_idx': order, 'order': [x for x in range(len(order))]})\n",
    "    order['station_id'] = order['modis_idx'].apply(lambda x: '-'.join(x.split('-')[:-1]))\n",
    "    order = order.merge(elev_order).sort_values('order')\n",
    "    ordered_elev = elevation[order['DEM_order'].to_list(), :, :]\n",
    "    dim = ordered_elev.shape\n",
    "\n",
    "    return np.concatenate([modis, ordered_elev.reshape(dim[0], 1, dim[1], dim[2])], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fbab25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentinel Helpers\n",
    "def y_merger(x, y):\n",
    "    '''reattach y labels to sentinel'''\n",
    "    y = y.rename(columns={\"Unnamed: 0\":\"cell_id\"})\n",
    "    y = pivot_df(y, 'cell_id').dropna()\n",
    "    y['date']=y['date'].map(daynum_gen)\n",
    "\n",
    "    y['idx'] = y['cell_id'] + \"-\" + y['date']\n",
    "    y = y.set_index('idx')\n",
    "\n",
    "    x['idx'] = x['cell_id'] +\\\n",
    "         \"-\" +x['date_long'].astype(str)\n",
    "    x = x.set_index('idx')\n",
    "\n",
    "    return x.join(y['snowpack'])\n",
    "\n",
    "#preprocessing helpers\n",
    "def masker(x,y):\n",
    "#     return x , y\n",
    "    mask = np.all(x > -99, axis = (1,2))\n",
    "    print(mask.sum(), \"of\", len(mask))\n",
    "    \n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def minmaxscaler(x):\n",
    "    print(\"min\", round(x.min(),3), \"max\", round(x.max(),3))\n",
    "    x = (x - x.min())/(x.max() - x.min())\n",
    "                   \n",
    "    return x\n",
    "\n",
    "def reshaper(ds):\n",
    "    #readjust dimensions\n",
    "    dim0 = ds.shape[0]\n",
    "    dim1 = ds.shape[1]\n",
    "    dim2 = ds.shape[2]\n",
    "\n",
    "    return ds.reshape((dim0, 1, dim1, dim2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd890158",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/\"\n",
    "\n",
    "#@title Original data\n",
    "metadata = pd.read_csv(DATA_PATH + 'ground_measures_metadata.csv')\n",
    "train_inp = pd.read_csv(DATA_PATH + 'ground_measures_train_features.csv')\n",
    "test_inp = pd.read_csv(DATA_PATH + 'ground_measures_test_features.csv')\n",
    "train_labels = pd.read_csv(DATA_PATH + 'train_labels.csv')\n",
    "grid_cells = gpd.read_file(DATA_PATH + 'grid_cells.geojson')\n",
    "submission_format = gpd.read_file(DATA_PATH + 'submission_format.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c7e62",
   "metadata": {},
   "source": [
    "## Sentinel Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50aa787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_14724\\1111496563.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  cell_metadata['centroid'] = cell_metadata['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "#@title Get metadata for grid cells\n",
    "states = gpd.read_file('C:/Users/Matt/Documents/Python Scripts/SnowComp/dat/states/')\\\n",
    "    .rename({'NAME': 'state'}, axis=1)\n",
    "states = states.to_crs('EPSG:4326')\n",
    "\n",
    "cell_metadata = gpd.sjoin(grid_cells, states[['geometry', 'state']])\\\n",
    "    .drop_duplicates(subset='cell_id')\\\n",
    "    .drop(['index_right'], axis=1)\n",
    "cell_metadata['centroid'] = cell_metadata['geometry'].centroid\n",
    "cell_metadata['longitude'] = cell_metadata['centroid'].x\n",
    "cell_metadata['latitude'] = cell_metadata['centroid'].y\n",
    "cell_metadata = cell_metadata[['cell_id', 'state', 'longitude', 'latitude']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df540fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Format dfs\n",
    "def get_rmse(df, actual='actual_snowpack', predicted='snowpack'):\n",
    "    return ((df[actual] - df[predicted]) ** 2).mean() ** 0.5\n",
    "\n",
    "def pivot_df(df, id_col, ignore_cols=None):\n",
    "    if not ignore_cols:\n",
    "        ignore_cols = []\n",
    "    date_cols = [x for x in df.columns if x not in [id_col] + ignore_cols]\n",
    "    dfs = []\n",
    "    for day in date_cols:\n",
    "        day_df = df[[id_col, day]].rename({day: 'snowpack'}, axis=1)\n",
    "        day_df['date'] = day\n",
    "        dfs.append(day_df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_day_of_season(doy):\n",
    "    return doy + 365 - 335 if doy < 335 else doy - 335\n",
    "\n",
    "def add_time_cols(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['doy'] = df['date'].dt.dayofyear\n",
    "    df['dos'] = df['doy'].apply(get_day_of_season)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['season'] = df['year']\n",
    "    df.loc[df['doy'] < 335, 'season'] -= 1\n",
    "    return df\n",
    "\n",
    "def clean_train_test(df, id_col='station_id', metadata_df=None):\n",
    "    df = pivot_df(df, id_col)\n",
    "    if metadata_df is not None:\n",
    "        df = df.merge(metadata_df)\n",
    "    return add_time_cols(df)\n",
    "\n",
    "def permuter(narray, df, rng= rng):\n",
    "    df.reset_index(inplace= True)\n",
    "    p =rng.permutation(len(narray))\n",
    "    \n",
    "    return narray[p], df.loc[p]\n",
    "\n",
    "train = clean_train_test(train_inp.rename({'Unnamed: 0': 'station_id'}, axis=1),\n",
    "                         metadata_df=metadata)\n",
    "train2 = clean_train_test(train_labels, 'cell_id', cell_metadata).dropna()\n",
    "train_full = pd.concat([train2.rename({'cell_id': 'station_id'}, axis=1).assign(datatype='labels'),\n",
    "                        train.drop(['elevation_m', 'name'], axis=1).assign(datatype='ground')])\n",
    "\n",
    "test = clean_train_test(\n",
    "    test_inp.rename({'Unnamed: 0': 'station_id'}, axis=1), metadata_df=metadata)\\\n",
    "    .rename({'snowpack': 'actual_snowpack'}, axis=1).dropna()\\\n",
    "    .merge(train[['station_id', 'state']].drop_duplicates())\n",
    "\n",
    "to_predict = clean_train_test(submission_format.drop('geometry', axis=1), 'cell_id', cell_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f147d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_path = \"C:/Users/Matt/Dropbox/SnowComp/SentinelHelper/\"\n",
    "\n",
    "sentinel_trainfeat = np.load(sent_path + \"sent_pp_trainfeat.npy\")\n",
    "sentinel_testfeat = np.load(sent_path + \"sent_pp_testfeat.npy\")\n",
    "sentinel_ylabs = np.load(sent_path + \"sent_pp_ylabs.npy\")\n",
    "\n",
    "trainfeat_meta = pd.read_csv(sent_path + \"sent_trainfeat_meta.csv\")\n",
    "testfeat_meta = pd.read_csv(sent_path + \"sent_testfeat_meta.csv\")\n",
    "ylabs_meta = pd.read_csv(sent_path + \"sent_ylabs_meta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ff641",
   "metadata": {},
   "source": [
    "### Merge back in y labels, mask NAs\n",
    "\n",
    "CHECK order not adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52a2195b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76159 of 76410\n",
      "105571 of 106760\n",
      "38618 of 38628\n",
      "min -57.906 max 18.57\n",
      "min -50.229 max 19.536\n",
      "min -27.488 max 14.445\n"
     ]
    }
   ],
   "source": [
    "sentinel_ylabs, ylabs_meta = masker(sentinel_ylabs, ylabs_meta)\n",
    "sentinel_trainfeat, trainfeat_meta = masker(sentinel_trainfeat, trainfeat_meta)\n",
    "sentinel_testfeat, testfeat_meta = masker(sentinel_testfeat, testfeat_meta)\n",
    "\n",
    "sentinel_ylabs = minmaxscaler(sentinel_ylabs)\n",
    "sentinel_trainfeat = minmaxscaler(sentinel_trainfeat)\n",
    "sentinel_testfeat = minmaxscaler(sentinel_testfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2b7a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([sentinel_trainfeat, sentinel_ylabs])\n",
    "train_y = pd.concat([trainfeat_meta, ylabs_meta])\n",
    "train_y['date'] = pd.to_datetime(train_y['date'])\n",
    "train_y = train_y.merge(train_full.rename({'station_id': 'cell_id'}, axis=1)\\\n",
    "                                    [['cell_id', 'snowpack', 'date']])\n",
    "\n",
    "testfeat_meta['date'] = pd.to_datetime(testfeat_meta['date'])\n",
    "sentinel_ylab_test = testfeat_meta.merge(\n",
    "    test.rename({'station_id': 'cell_id', 'actual_snowpack': 'snowpack'}, axis=1)\\\n",
    "    [['cell_id', 'snowpack', 'date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4216aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinel_testfeat, sentinel_ylab_test\n",
    "del sentinel_ylabs\n",
    "del ylabs_meta\n",
    "del sentinel_trainfeat\n",
    "del trainfeat_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282c6c3",
   "metadata": {},
   "source": [
    "## Define Training and Testing Sets\n",
    "\n",
    "\n",
    "`dataset -> sentinel_ylabs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "933d1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664086aa",
   "metadata": {},
   "source": [
    "## Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6269558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define simple CNN\n",
    "# From: https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html\n",
    "# Also used: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "START_D = 1\n",
    "START_HW = 41\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def _conv_calc(self, in_dim, pad, stride, k):\n",
    "        out = int(np.floor((in_dim + 2 * pad - (k - 1) - 1) / stride + 1))\n",
    "        return out\n",
    "\n",
    "    def __init__(self, cdim1, cdim2, cdim3, kernel_sz, dropout,\n",
    "                 ldim, print_dim = True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #first layer\n",
    "        self.conv1 = nn.Conv2d(START_D, cdim1, kernel_sz, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3, stride= 1)\n",
    "        \n",
    "        c1_dim = self._conv_calc(START_HW, 0, 1, kernel_sz)\n",
    "        mp0_dim = self._conv_calc(c1_dim, 0, 1, 3)\n",
    "        \n",
    "        #second layer\n",
    "        self.conv2 = nn.Conv2d(cdim1, cdim2, kernel_sz, 1)\n",
    "        c2_dim = self._conv_calc(mp0_dim, 0, 1, kernel_sz)\n",
    "        mp1_dim = self._conv_calc(c2_dim, 0, 1, 3)\n",
    "        \n",
    "        #third layer\n",
    "        self.conv3_ = nn.Conv2d(cdim3, cdim3, kernel_sz, 1)\n",
    "        self.conv3 = nn.Conv2d(cdim2, cdim3, kernel_sz, 1)\n",
    "        c3_dim = self._conv_calc(mp1_dim, 0, 1, kernel_sz)\n",
    "        c3__dim = self._conv_calc(c3_dim, 0, 1, kernel_sz)\n",
    "        c3___dim = self._conv_calc(c3_dim, 0, 1, kernel_sz)\n",
    "        mp2_dim = self._conv_calc(c3___dim, 0, 1, 3)\n",
    "        \n",
    "        #fourth layer\n",
    "        print(cdim3, mp2_dim, mp2_dim)\n",
    "        flattened_dim = cdim3 * mp2_dim * mp2_dim\n",
    "        self.fc1 = nn.Linear(200, ldim)\n",
    "        self.fc2 = nn.Linear(ldim, 1)\n",
    "\n",
    "        #extras\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        self.dropout2 = nn.Dropout2d(dropout*2)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(cdim1)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(cdim3)\n",
    "        \n",
    "        if print_dim:\n",
    "            print('c1 dim:', c1_dim)\n",
    "            print('mp0 dim:', mp0_dim)\n",
    "            print('c2 dim:', c2_dim)\n",
    "            print('mp1 dim:', mp1_dim)\n",
    "            print('c3 dim:', c3_dim)\n",
    "            print('c3_ dim:', c3__dim)\n",
    "            print('c3__ dim:', c3___dim)\n",
    "            print('mp2 dim:', mp2_dim)\n",
    "            print('flattened_dim', flattened_dim)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #first layer\n",
    "        x = self.conv1(x)\n",
    "        x = F.tanh(x)\n",
    "        # x = F.relu(x)\n",
    "        x = self.BatchNorm1(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        #second layer\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.tanh(x)\n",
    "        # x = F.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        #third layer\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "        \n",
    "        x = self.conv3_(x)\n",
    "        x = F.tanh(x)\n",
    "        \n",
    "        x = self.conv3_(x)\n",
    "        x = F.tanh(x)\n",
    "        # x = F.relu(x)\n",
    "        x = self.BatchNorm3(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        #fourth layer\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03c2043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helpers to get predictions and accuracy\n",
    "def predict(cnn, x, as_numpy=False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cnn.eval()\n",
    "    x = x.type(torch.FloatTensor).to(device)\n",
    "    output = cnn(x)\n",
    "    if as_numpy:\n",
    "        output = output.flatten().cpu().detach().numpy() #detach removes gradients (bad)\n",
    "        \n",
    "    cnn.train()\n",
    "    return output.squeeze()\n",
    "\n",
    "def get_accuracy(cnn, x, y):\n",
    "#     y = torch.from_numpy(y).to(device)\n",
    "    outputs = predict(cnn, x, as_numpy = False)\n",
    "    loss = ((y-outputs)**2).sum()\n",
    "    return round(loss.item(), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e6e6c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #@title Setup net\n",
    "# cdim1=60; cdim2=20; cdim3 =15; kernel_sz=3; dropout=0.13; ldim=40; lrate = 0.0003\n",
    "# my_nn = Net(cdim1=cdim1, cdim2=cdim2,cdim3 =cdim3, kernel_sz=kernel_sz, dropout=dropout, ldim=ldim)\n",
    "# optimizer = optim.Adam(my_nn.parameters(), lr=0.1)\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# # test_im = torch.from_numpy(dataset[0]).reshape(1, START_D, 21, 21)\n",
    "# test_im = torch.from_numpy(dataset[0]).reshape(1, START_D, 41, 41)\n",
    "# result = my_nn(test_im.type(torch.FloatTensor))\n",
    "# result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9742f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Get data loaders\n",
    "\n",
    "mini_x = np.array(dataset.reshape(dataset.shape[0], 1, 41, 41))\n",
    "mini_y = np.array(train_y['snowpack'])\n",
    "mini_x, mini_y = torch.Tensor(mini_x), torch.Tensor(mini_y)\n",
    "\n",
    "test_x = np.array(sentinel_testfeat.reshape(sentinel_testfeat.shape[0], 1, 41, 41))\n",
    "test_y = np.array(sentinel_ylab_test['snowpack'])\n",
    "test_x, test_y = torch.Tensor(test_x), torch.Tensor(test_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 200)\n",
    "\n",
    "mini_dataset = TensorDataset(mini_x, mini_y)\n",
    "mini_loader = DataLoader(mini_dataset, batch_size=200)\n",
    "\n",
    "train_rows = len(mini_x)\n",
    "test_rows = len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c554846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 11 11\n",
      "c1 dim: 35\n",
      "mp0 dim: 33\n",
      "c2 dim: 27\n",
      "mp1 dim: 25\n",
      "c3 dim: 19\n",
      "c3_ dim: 13\n",
      "c3__ dim: 13\n",
      "mp2 dim: 11\n",
      "flattened_dim 968\n"
     ]
    }
   ],
   "source": [
    "#@ title Setup net\n",
    "cdim1, cdim2, cdim3, kernel_sz, dropout, ldim, lr = 32, 18, 8, 7, 0.13, 16, 1e-4\n",
    "# cdim1, cdim2, cdim3, kernel_sz, dropout, ldim = 48, 18, 8, 3, 0.2, 50\n",
    "\n",
    "my_nn = Net(cdim1=cdim1, cdim2=cdim2, cdim3=cdim3, kernel_sz=kernel_sz, dropout=dropout, ldim=ldim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_nn.to(device)\n",
    "optimizer = optim.Adam(my_nn.parameters(), lr=lr)#0.00005)\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28edfa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9b21fba36c49aa972562b6628e8b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 90 complete, train: 17.4259 test: 12.1248 elapsed: 14\n",
      "1 / 90 complete, train: 16.0192 test: 11.169 elapsed: 28\n",
      "2 / 90 complete, train: 15.4497 test: 10.9092 elapsed: 43\n",
      "3 / 90 complete, train: 15.1285 test: 10.7236 elapsed: 57\n",
      "4 / 90 complete, train: 14.8938 test: 10.6178 elapsed: 73\n",
      "5 / 90 complete, train: 14.7215 test: 10.5599 elapsed: 88\n",
      "6 / 90 complete, train: 14.6433 test: 10.5354 elapsed: 102\n",
      "7 / 90 complete, train: 14.5467 test: 10.5319 elapsed: 116\n",
      "8 / 90 complete, train: 14.5001 test: 10.5412 elapsed: 131\n",
      "9 / 90 complete, train: 14.4609 test: 10.5681 elapsed: 145\n",
      "10 / 90 complete, train: 14.4368 test: 10.5768 elapsed: 159\n",
      "11 / 90 complete, train: 14.4219 test: 10.5966 elapsed: 173\n",
      "12 / 90 complete, train: 14.4218 test: 10.6205 elapsed: 188\n",
      "13 / 90 complete, train: 14.4135 test: 10.633 elapsed: 203\n",
      "14 / 90 complete, train: 14.3864 test: 10.6501 elapsed: 218\n",
      "15 / 90 complete, train: 14.4097 test: 10.6632 elapsed: 233\n",
      "16 / 90 complete, train: 14.4 test: 10.6885 elapsed: 247\n",
      "17 / 90 complete, train: 14.396 test: 10.6847 elapsed: 262\n",
      "18 / 90 complete, train: 14.3958 test: 10.6929 elapsed: 276\n",
      "19 / 90 complete, train: 14.3969 test: 10.6998 elapsed: 290\n",
      "20 / 90 complete, train: 14.3973 test: 10.7055 elapsed: 305\n",
      "21 / 90 complete, train: 14.3988 test: 10.7103 elapsed: 319\n",
      "22 / 90 complete, train: 14.3946 test: 11.6818 elapsed: 333\n",
      "23 / 90 complete, train: 14.6336 test: 10.7542 elapsed: 347\n",
      "24 / 90 complete, train: 14.3969 test: 10.7432 elapsed: 362\n",
      "25 / 90 complete, train: 14.4014 test: 10.7413 elapsed: 376\n",
      "26 / 90 complete, train: 14.5134 test: 10.7553 elapsed: 390\n",
      "27 / 90 complete, train: 14.3977 test: 10.7515 elapsed: 405\n",
      "28 / 90 complete, train: 14.4378 test: 10.7481 elapsed: 419\n",
      "29 / 90 complete, train: 14.4164 test: 10.7483 elapsed: 434\n",
      "30 / 90 complete, train: 14.3985 test: 10.7433 elapsed: 448\n",
      "31 / 90 complete, train: 14.3958 test: 10.7413 elapsed: 463\n",
      "32 / 90 complete, train: 14.3955 test: 10.7396 elapsed: 477\n",
      "33 / 90 complete, train: 14.3977 test: 10.7382 elapsed: 491\n",
      "34 / 90 complete, train: 14.3979 test: 10.7406 elapsed: 506\n",
      "35 / 90 complete, train: 14.3956 test: 10.7391 elapsed: 520\n",
      "36 / 90 complete, train: 14.3968 test: 10.7379 elapsed: 535\n",
      "37 / 90 complete, train: 14.3978 test: 10.7367 elapsed: 549\n",
      "38 / 90 complete, train: 14.3985 test: 10.7364 elapsed: 564\n",
      "39 / 90 complete, train: 14.3954 test: 10.7356 elapsed: 579\n",
      "40 / 90 complete, train: 14.3971 test: 10.7358 elapsed: 593\n",
      "41 / 90 complete, train: 14.3953 test: 10.7352 elapsed: 608\n",
      "42 / 90 complete, train: 14.3955 test: 10.7348 elapsed: 622\n",
      "43 / 90 complete, train: 14.3853 test: 10.7375 elapsed: 637\n",
      "44 / 90 complete, train: 14.3953 test: 10.7366 elapsed: 651\n",
      "45 / 90 complete, train: 14.3955 test: 10.7362 elapsed: 666\n",
      "46 / 90 complete, train: 14.396 test: 10.7357 elapsed: 680\n",
      "47 / 90 complete, train: 14.3964 test: 10.7352 elapsed: 694\n",
      "48 / 90 complete, train: 14.3961 test: 10.7348 elapsed: 709\n",
      "49 / 90 complete, train: 14.3957 test: 10.7351 elapsed: 723\n",
      "50 / 90 complete, train: 14.3962 test: 10.7348 elapsed: 737\n",
      "51 / 90 complete, train: 14.3953 test: 10.7346 elapsed: 751\n",
      "52 / 90 complete, train: 14.3964 test: 10.7339 elapsed: 766\n",
      "53 / 90 complete, train: 14.3966 test: 10.7337 elapsed: 780\n",
      "54 / 90 complete, train: 14.3952 test: 10.7336 elapsed: 796\n",
      "55 / 90 complete, train: 14.3953 test: 10.7334 elapsed: 812\n",
      "56 / 90 complete, train: 14.3953 test: 10.7332 elapsed: 827\n",
      "57 / 90 complete, train: 14.3955 test: 10.7331 elapsed: 842\n",
      "58 / 90 complete, train: 14.396 test: 10.733 elapsed: 857\n",
      "59 / 90 complete, train: 14.3955 test: 10.733 elapsed: 871\n",
      "60 / 90 complete, train: 14.3954 test: 10.7329 elapsed: 885\n",
      "61 / 90 complete, train: 14.3958 test: 10.7327 elapsed: 899\n",
      "62 / 90 complete, train: 14.3962 test: 10.7327 elapsed: 914\n",
      "63 / 90 complete, train: 14.3963 test: 10.7324 elapsed: 929\n",
      "64 / 90 complete, train: 14.3955 test: 10.7324 elapsed: 944\n",
      "65 / 90 complete, train: 14.3952 test: 10.7323 elapsed: 960\n",
      "66 / 90 complete, train: 14.3951 test: 10.7323 elapsed: 975\n",
      "67 / 90 complete, train: 14.3951 test: 10.7321 elapsed: 990\n",
      "68 / 90 complete, train: 14.3954 test: 10.7321 elapsed: 1005\n",
      "69 / 90 complete, train: 14.3951 test: 10.7321 elapsed: 1020\n",
      "70 / 90 complete, train: 14.3952 test: 10.7321 elapsed: 1034\n",
      "71 / 90 complete, train: 14.3951 test: 10.732 elapsed: 1049\n",
      "72 / 90 complete, train: 14.3953 test: 10.732 elapsed: 1064\n",
      "73 / 90 complete, train: 14.3951 test: 10.732 elapsed: 1079\n",
      "74 / 90 complete, train: 14.3952 test: 10.732 elapsed: 1094\n",
      "75 / 90 complete, train: 14.3956 test: 10.732 elapsed: 1109\n",
      "76 / 90 complete, train: 14.3965 test: 10.7324 elapsed: 1123\n",
      "77 / 90 complete, train: 14.3955 test: 10.7324 elapsed: 1138\n",
      "78 / 90 complete, train: 14.399 test: 10.733 elapsed: 1153\n",
      "79 / 90 complete, train: 14.3967 test: 10.7328 elapsed: 1168\n",
      "80 / 90 complete, train: 14.3957 test: 10.7327 elapsed: 1183\n",
      "81 / 90 complete, train: 14.3953 test: 10.7325 elapsed: 1197\n",
      "82 / 90 complete, train: 14.3952 test: 10.7324 elapsed: 1212\n",
      "83 / 90 complete, train: 14.3954 test: 10.7324 elapsed: 1227\n",
      "84 / 90 complete, train: 14.3951 test: 10.7324 elapsed: 1242\n",
      "85 / 90 complete, train: 14.3951 test: 10.7323 elapsed: 1257\n",
      "86 / 90 complete, train: 14.3951 test: 10.7323 elapsed: 1271\n",
      "87 / 90 complete, train: 14.4094 test: 10.734 elapsed: 1286\n",
      "88 / 90 complete, train: 14.3994 test: 10.7345 elapsed: 1301\n",
      "89 / 90 complete, train: 14.3957 test: 10.7338 elapsed: 1316\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#@title Run net\n",
    "N_EPOCHS = 90\n",
    "\n",
    "test_loss = []\n",
    "train_loss = []\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(mini_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = my_nn(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "#         if (i + 1) % 100 == 0:\n",
    "#             writer.add_scalar('Loss/train', running_loss , write_index)\n",
    "#         write_index += 1\n",
    "\n",
    "    train_loss.append(running_loss/train_rows)\n",
    "#     writer.add_scalar('Acc/val', train_loss[-1], write_index)\n",
    "    \n",
    "    #calculate test loss.\n",
    "    with torch.no_grad():        \n",
    "        running_tar_loss = 0\n",
    "        for data, target in test_loader:\n",
    "            running_tar_loss += get_accuracy(my_nn, data, target.to(device))\n",
    "\n",
    "\n",
    "        test_loss.append(running_tar_loss / test_rows)\n",
    "#         writer.add_scalar('Test MSE', test_loss[-1], write_index)\n",
    "\n",
    "    print(epoch, '/', N_EPOCHS,\n",
    "          'complete, train:', round(np.sqrt(train_loss[-1]), 4),\n",
    "          \"test:\", round(np.sqrt(test_loss[-1]), 4),\n",
    "          'elapsed:', round(time.time() - t0))\n",
    "    \n",
    "# writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "499a8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1801a",
   "metadata": {},
   "source": [
    "### Checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca529682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"C:/Users/Matt/Dropbox/SnowComp/RunGraphs/\" \n",
    "\n",
    "suffix = \"_\" + \\\n",
    "    str(cdim1)+ \"_\" + str(cdim2)+ \"_\" +str(cdim3)+ \"_\" + str(kernel_sz)+ \\\n",
    "    \"_\" + str(dropout)+ \"_\" + str(ldim)+ \"_\" + str(epoch) +\"_\" + str(lrate)\n",
    "\n",
    "plt.plot(range(epoch+1), np.sqrt(train_loss), label =\"train\")\n",
    "plt.plot(range(epoch+1), np.sqrt(test_loss), label =\"test\")\n",
    "plt.legend()\n",
    "plt.savefig(path +\"sent_converge_alldata\" + suffix+ \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad3627",
   "metadata": {},
   "source": [
    "## Save Model and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede0078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "530808f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = True\n",
    "if pred_all:\n",
    "    full_x = np.concatenate((dataset.reshape(dataset.shape[0], 1, 41, 41),\n",
    "               sentinel_testfeat.reshape(sentinel_testfeat.shape[0], 1, 41, 41)),\n",
    "              axis= 0)\n",
    "\n",
    "    full_y_meta = pd.concat((train_y, sentinel_ylab_test),\n",
    "                           axis = 0)\n",
    "\n",
    "    full_x, full_y_meta = permuter(full_x, full_y_meta)\n",
    "    full_y = np.array(full_y_meta['snowpack'])\n",
    "    \n",
    "    full_x, full_y = torch.Tensor(full_x), torch.Tensor(full_y)\n",
    "    full_dataset = TensorDataset(full_x, full_y)\n",
    "    full_loader = DataLoader(full_dataset, batch_size=200)\n",
    "    \n",
    "    del dataset, sentinel_testfeat, train_y, sentinel_ylab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "abb98e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 11 11\n",
      "c1 dim: 35\n",
      "mp0 dim: 33\n",
      "c2 dim: 27\n",
      "mp1 dim: 25\n",
      "c3 dim: 19\n",
      "c3_ dim: 13\n",
      "c3__ dim: 13\n",
      "mp2 dim: 11\n",
      "flattened_dim 968\n"
     ]
    }
   ],
   "source": [
    "if pred_all:\n",
    "    #@title Setup net\n",
    "    my_nn = Net(cdim1=cdim1, cdim2=cdim2,cdim3 =cdim3,\n",
    "                kernel_sz=kernel_sz, dropout=dropout, ldim=ldim)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    my_nn.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(my_nn.parameters(), lr=lrate)\n",
    "    criterion = nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e228f33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba71853f24124c46b45409bffd5c470a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 90 complete, train: 17.4508 test: 10.7338\n",
      "1 / 90 complete, train: 15.3834 test: 10.7338\n",
      "2 / 90 complete, train: 15.2146 test: 10.7338\n",
      "3 / 90 complete, train: 15.2052 test: 10.7338\n",
      "4 / 90 complete, train: 15.2014 test: 10.7338\n",
      "5 / 90 complete, train: 15.1933 test: 10.7338\n",
      "6 / 90 complete, train: 15.1979 test: 10.7338\n",
      "7 / 90 complete, train: 15.1916 test: 10.7338\n",
      "8 / 90 complete, train: 15.1899 test: 10.7338\n",
      "9 / 90 complete, train: 15.1881 test: 10.7338\n",
      "10 / 90 complete, train: 15.1861 test: 10.7338\n",
      "11 / 90 complete, train: 15.1628 test: 10.7338\n",
      "12 / 90 complete, train: 15.1746 test: 10.7338\n",
      "13 / 90 complete, train: 15.1554 test: 10.7338\n",
      "14 / 90 complete, train: 15.1391 test: 10.7338\n",
      "15 / 90 complete, train: 15.1177 test: 10.7338\n",
      "16 / 90 complete, train: 15.0501 test: 10.7338\n",
      "17 / 90 complete, train: 14.9821 test: 10.7338\n",
      "18 / 90 complete, train: 14.9317 test: 10.7338\n",
      "19 / 90 complete, train: 14.877 test: 10.7338\n",
      "20 / 90 complete, train: 14.836 test: 10.7338\n",
      "21 / 90 complete, train: 14.8108 test: 10.7338\n",
      "22 / 90 complete, train: 14.7694 test: 10.7338\n",
      "23 / 90 complete, train: 14.7418 test: 10.7338\n",
      "24 / 90 complete, train: 14.7204 test: 10.7338\n",
      "25 / 90 complete, train: 14.7008 test: 10.7338\n",
      "26 / 90 complete, train: 14.675 test: 10.7338\n",
      "27 / 90 complete, train: 14.6449 test: 10.7338\n",
      "28 / 90 complete, train: 14.6229 test: 10.7338\n",
      "29 / 90 complete, train: 14.6017 test: 10.7338\n",
      "30 / 90 complete, train: 14.5748 test: 10.7338\n",
      "31 / 90 complete, train: 14.5489 test: 10.7338\n",
      "32 / 90 complete, train: 14.5469 test: 10.7338\n",
      "33 / 90 complete, train: 14.5228 test: 10.7338\n",
      "34 / 90 complete, train: 14.509 test: 10.7338\n",
      "35 / 90 complete, train: 14.5002 test: 10.7338\n",
      "36 / 90 complete, train: 14.4773 test: 10.7338\n",
      "37 / 90 complete, train: 14.4615 test: 10.7338\n",
      "38 / 90 complete, train: 14.4427 test: 10.7338\n",
      "39 / 90 complete, train: 14.4264 test: 10.7338\n",
      "40 / 90 complete, train: 14.4091 test: 10.7338\n",
      "41 / 90 complete, train: 14.4077 test: 10.7338\n",
      "42 / 90 complete, train: 14.3874 test: 10.7338\n",
      "43 / 90 complete, train: 14.3799 test: 10.7338\n",
      "44 / 90 complete, train: 14.3602 test: 10.7338\n",
      "45 / 90 complete, train: 14.3442 test: 10.7338\n",
      "46 / 90 complete, train: 14.3326 test: 10.7338\n",
      "47 / 90 complete, train: 14.3293 test: 10.7338\n",
      "48 / 90 complete, train: 14.3133 test: 10.7338\n",
      "49 / 90 complete, train: 14.3157 test: 10.7338\n",
      "50 / 90 complete, train: 14.2976 test: 10.7338\n",
      "51 / 90 complete, train: 14.2897 test: 10.7338\n",
      "52 / 90 complete, train: 14.2824 test: 10.7338\n",
      "53 / 90 complete, train: 14.2655 test: 10.7338\n",
      "54 / 90 complete, train: 14.2763 test: 10.7338\n",
      "55 / 90 complete, train: 14.2561 test: 10.7338\n",
      "56 / 90 complete, train: 14.2434 test: 10.7338\n",
      "57 / 90 complete, train: 14.2443 test: 10.7338\n",
      "58 / 90 complete, train: 14.2284 test: 10.7338\n",
      "59 / 90 complete, train: 14.2187 test: 10.7338\n",
      "60 / 90 complete, train: 14.2192 test: 10.7338\n",
      "61 / 90 complete, train: 14.199 test: 10.7338\n",
      "62 / 90 complete, train: 14.1918 test: 10.7338\n",
      "63 / 90 complete, train: 14.1939 test: 10.7338\n",
      "64 / 90 complete, train: 14.1723 test: 10.7338\n",
      "65 / 90 complete, train: 14.1721 test: 10.7338\n",
      "66 / 90 complete, train: 14.1578 test: 10.7338\n",
      "67 / 90 complete, train: 14.1562 test: 10.7338\n",
      "68 / 90 complete, train: 14.1443 test: 10.7338\n",
      "69 / 90 complete, train: 14.1369 test: 10.7338\n",
      "70 / 90 complete, train: 14.1233 test: 10.7338\n",
      "71 / 90 complete, train: 14.1256 test: 10.7338\n",
      "72 / 90 complete, train: 14.1207 test: 10.7338\n",
      "73 / 90 complete, train: 14.1068 test: 10.7338\n",
      "74 / 90 complete, train: 14.0908 test: 10.7338\n",
      "75 / 90 complete, train: 14.094 test: 10.7338\n",
      "76 / 90 complete, train: 14.0825 test: 10.7338\n",
      "77 / 90 complete, train: 14.0981 test: 10.7338\n",
      "78 / 90 complete, train: 14.0797 test: 10.7338\n",
      "79 / 90 complete, train: 14.0688 test: 10.7338\n",
      "80 / 90 complete, train: 14.0689 test: 10.7338\n",
      "81 / 90 complete, train: 14.0611 test: 10.7338\n",
      "82 / 90 complete, train: 14.0494 test: 10.7338\n",
      "83 / 90 complete, train: 14.0469 test: 10.7338\n",
      "84 / 90 complete, train: 14.0328 test: 10.7338\n",
      "85 / 90 complete, train: 14.0288 test: 10.7338\n",
      "86 / 90 complete, train: 14.0219 test: 10.7338\n",
      "87 / 90 complete, train: 14.0247 test: 10.7338\n",
      "88 / 90 complete, train: 13.9941 test: 10.7338\n",
      "89 / 90 complete, train: 14.0001 test: 10.7338\n",
      "90 / 90 complete, train: 14.0029 test: 10.7338\n",
      "91 / 90 complete, train: 13.9928 test: 10.7338\n",
      "92 / 90 complete, train: 13.9972 test: 10.7338\n",
      "93 / 90 complete, train: 13.9742 test: 10.7338\n",
      "94 / 90 complete, train: 13.9874 test: 10.7338\n",
      "95 / 90 complete, train: 13.9708 test: 10.7338\n",
      "96 / 90 complete, train: 13.9834 test: 10.7338\n",
      "97 / 90 complete, train: 13.9538 test: 10.7338\n",
      "98 / 90 complete, train: 13.9469 test: 10.7338\n"
     ]
    }
   ],
   "source": [
    "if pred_all:\n",
    "    train_loss = []\n",
    "\n",
    "    #@title Run net\n",
    "    for epoch in tqdm(range(int(N_EPOCHS*1.1))):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(full_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            outputs = my_nn(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss.append(running_loss/train_rows)\n",
    "        print(epoch, '/', N_EPOCHS,\n",
    "              'complete, train:', round(np.sqrt(train_loss[-1]), 4),\n",
    "              \"test:\", round(np.sqrt(test_loss[-1]), 4) )\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8dbe6b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if pred_all:\n",
    "    path = \"C:/Users/Matt/Dropbox/SnowComp/RunGraphs/\" \n",
    "\n",
    "    suffix = \"_\" + \\\n",
    "        str(cdim1)+ \"_\" + str(cdim2)+ \"_\" +str(cdim3)+ \"_\" + str(kernel_sz)+ \\\n",
    "        \"_\" + str(dropout)+ \"_\" + str(ldim)+ \"_\" + str(epoch) +\"_\" + str(lrate) \n",
    "\n",
    "    plt.plot(range(epoch+1), np.sqrt(train_loss), label =\"train\")\n",
    "    plt.legend()\n",
    "    plt.savefig(path +\"sent\" + suffix+ \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c4a74810",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_all:\n",
    "    my_nn.eval()\n",
    "\n",
    "    torch.save(my_nn.state_dict(), path +\"model_sent\"+suffix)\n",
    "\n",
    "    vals = []\n",
    "    for inputs, _ in full_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(device)\n",
    "            vals.append(my_nn(inputs).cpu().numpy())\n",
    "    vals =  np.concatenate(vals, axis = 0)       \n",
    "\n",
    "    path_preds = \"C:/Users/Matt/Dropbox/SnowComp/preds/\" \n",
    "    np.save(path_preds+\"sentpreds.npy\", vals)\n",
    "\n",
    "    data_path = \"C:/Users/Matt/Dropbox/SnowComp/FinalData/\"\n",
    "    full_y_meta.to_csv(data_path +\"sent_ymeta.csv\")\n",
    "    \n",
    "    del full_x, full_y, full_y_meta, full_dataset, full_loader, vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b81a0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_all:\n",
    "    sub1_meta = pd.read_csv(sent_path + \"sent_sub1_meta.csv\")\n",
    "    sub2_meta = pd.read_csv(sent_path + \"sent_sub2_meta.csv\")\n",
    "    sub_ds1 = np.load(sent_path + \"sent_pp_sub1.npy\")\n",
    "    sub_ds2 = np.load(sent_path + \"sent_pp_sub2.npy\")\n",
    "\n",
    "    sub_meta = pd.concat((sub1_meta, sub2_meta), axis = 0)\n",
    "    sub_dataset = np.concatenate((sub_ds1, sub_ds2), axis = 0)\n",
    "    \n",
    "    sub_dataset = sub_dataset.reshape((-1, 1, 41, 41))\n",
    "    del sub1_meta, sub2_meta, sub_ds1, sub_ds2\n",
    "\n",
    "# sub_meta = np.array(sub_meta['snowpack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f932652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 41, 41])\n"
     ]
    }
   ],
   "source": [
    "for images in sub_loader:\n",
    "    print(images[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f26846a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\miniconda3\\envs\\pytorch_gp\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "if pred_all:\n",
    "    #Predict and save on submission data\n",
    "    vals_sub = []\n",
    "    \n",
    "    sub_dataset = torch.Tensor(sub_dataset)\n",
    "    sub_ds = TensorDataset(sub_dataset)\n",
    "    sub_loader = DataLoader(sub_ds, batch_size=5000)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in sub_loader:\n",
    "            images = images[0].to(device)\n",
    "            vals_sub.append(my_nn(images).cpu().numpy()) \n",
    "\n",
    "    vals_sub = np.concatenate(vals_sub, axis = 0)        \n",
    "    np.save(path_preds+\"sent_subpred.npy\", vals_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d759f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
